"""
Module de gÃ©nÃ©ration dâ€™un plan dâ€™action structurÃ© Ã  partir du POA dâ€™un patient.

Ce module est dÃ©clenchÃ© lorsque lâ€™intention Â« generate_recommendations Â» est dÃ©tectÃ©e.
Il extrait le nom du patient, charge et nettoie le document POA, anonymise les donnÃ©es,
puis interroge un modÃ¨le LLM avec un prompt enrichi pour gÃ©nÃ©rer des recommandations classÃ©es
(par type d'action : prÃ©vention, soins, traitements, etc.).
"""

from src.func.poa_loader import load_patient_file
from src.func.poa_cleaning import clean_patient_document
from src.func.detect_poa_file_path import extract_relevant_info
from src.llm_user_session.model import llm_model
from src.func.extract_patient_name import extract_patient_name_llm
from src.func.anonymizer import anonymize_patient_document
from src.func.anonymizer import deanonymize_fields
from src.utils.convert_json_text import convert_json_to_text
from src.func.llm_prompts import (rag_llm_prompt_template_medical_plan,
                                  rag_medical_response_from_llm)
from src.func.free_text_name_anonymizer import anonymize_name_mentions_in_free_text


import tiktoken
import json
import traceback



def generate_structured_medical_plan(user_input, system_prompt):
    """
    GÃ©nÃ¨re un plan dâ€™action structurÃ© Ã  partir du POA du patient mentionnÃ© dans la requÃªte utilisateur.

    Ã‰tapes :
    - Extraction du nom du patient.
    - Chargement et nettoyage du fichier POA.
    - Anonymisation des donnÃ©es.
    - Conversion en texte structurÃ©.
    - GÃ©nÃ©ration de recommandations via un modÃ¨le LLM.
    - DÃ©sanonymisation de la rÃ©ponse.

    Args:
        user_input (str): RequÃªte utilisateur contenant le nom du patient.
        system_prompt (str): Prompt systÃ¨me de base transmis au modÃ¨le.

    Returns:
        tuple:
            - str : Recommandations structurÃ©es par type dâ€™action mÃ©dicale.
            - dict : Dictionnaire de mapping dâ€™anonymisation utilisÃ©.
    """

    print("ğŸ“¥ DÃ©but gÃ©nÃ©ration du plan structurÃ© mÃ©dical...")
    print(f'generate_structured_medical_plan.py/user_input: {user_input}')


    # ============================================
    # 1. Extraire le nom du patient
    # ============================================
    patient_name = extract_patient_name_llm(user_input)
    if not patient_name:
        return "âŒ Impossible de dÃ©terminer le nom du patient Ã  partir de la requÃªte."

    print(f"ğŸŸ¢ Recherche du fichier avec patient_name = '{patient_name}'")



    # ============================================
    # 2. RÃ©cupÃ©rer le chemin du fichier patient
    # ============================================
    print(f'patient_name: {patient_name}')
    patient_file_path = extract_relevant_info(patient_name)
    print(f'patient_file_path: {patient_file_path}')
    if not patient_file_path:
        return f"âŒ Fichier du patient {patient_name} introuvable."



    # ============================================
    # 3. Charger le fichier patient
    # ============================================
    try:
        raw_document = load_patient_file(patient_file_path)
        if not raw_document:
            print('No raw_document available')
    except FileNotFoundError:
        return f"âŒ Impossible de charger le fichier du patient {patient_name}."
    print("âœ… Chargement du document terminÃ©.")
    # print("ğŸ” AperÃ§u du JSON brut :", json.dumps(raw_document, indent=2, ensure_ascii=False)[:1000])



    # ============================================
    # 4. Nettoyer le contenu du fichier (POA)
    # ============================================
    if not raw_document:
        print('No raw_document available')
    cleaned_document = clean_patient_document(raw_document)
    print("âœ… Document nettoyÃ©.")
    print(f"ğŸŸ¡ Type de l'output - Document nettoyÃ©:, {type(cleaned_document)}")


    # ============================================
    # 4. Bis Anonymisation du POA + conversion dictionnaire en texte
    # ============================================
    anonymized_doc, dict_mapping = anonymize_patient_document(cleaned_document, debug=False)
    anonymized_doc, dict_mapping = anonymize_name_mentions_in_free_text(anonymized_doc, dict_mapping, debug=False)

    print("âœ… Anonymisation effectuÃ©e.")
    print("ğŸ” Texte anonymisÃ© :", json.dumps(anonymized_doc, indent=2, ensure_ascii=False)[0][:300])
    print("ğŸ“Œ Exemple de mapping :", list(dict_mapping.items())[:10])

    print(f"AprÃ¨s anonymisation -> {anonymized_doc}")

    anonymized_text = convert_json_to_text(anonymized_doc)
    print("âœ… Conversion JSON â†’ texte rÃ©ussie.")
    # print("ğŸ” Prompt envoyÃ© au modÃ¨le :", anonymized_text)



    # ============================================
    #5. encapsule le prompt de base pour ce type d'analyse mÃ©dicale.
    # ============================================
    try:
        print("ğŸ“„ Appel Ã  rag_llm_prompt_template_medical_plan")
        prompt_template = rag_llm_prompt_template_medical_plan()
        print("ğŸ” Type rÃ©el de prompt_template :", type(prompt_template))
        print("âœ… Variables attendues :", prompt_template.input_variables)

    except Exception as e:
        print(f"âŒ Erreur lors de lâ€™appel Ã  rag_llm_prompt_template_medical_plan : {type(e).__name__} - {e}")
        traceback.print_exc()
        return "âŒ Erreur lors de l'extraction du prompt_template.", dict_mapping



    print("ğŸ“„ Appel Ã  rag_medical_response_from_llm()")
    # ============================================
    # 6. centralise l'appel au modÃ¨le avec un StrOutputParser
    # ============================================
    try:
        print("ğŸ“„ Appel Ã  rag_medical_response_from_llm()")
        response = rag_medical_response_from_llm(prompt_template, user_input, anonymized_text)
        print("ğŸ“„ RÃ©ponse obtenue du LLM")
        # print(f"ğŸŸ¢ RÃ©ponse brute du modÃ¨le : {response}")
    except Exception as e:
        print(f"âŒ Erreur lors de lâ€™appel Ã  rag_medical_response_from_llm : {type(e).__name__} - {e}")
        traceback.print_exc()
        return "âŒ Erreur lors de l'appel au modÃ¨le LLM pour les recommandations.", dict_mapping


    # ============================================
    # 7. response = llm_model.invoke(final_prompt)
    # ============================================
    try:
        deanonymized_response, reverse_mapping = deanonymize_fields(response, dict_mapping, debug=True)

    except Exception as e:
        print(f"âŒ Erreur lors de la dÃ©sanonymisation : {type(e).__name__} - {e}")
        traceback.print_exc()
        return "âŒ Erreur lors de la dÃ©sanonymisation des recommandations.", dict_mapping


    # ============================================
    # 8. Extraction propre du contenu
    # ============================================
    return deanonymized_response.strip(), dict_mapping


