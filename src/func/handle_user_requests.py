"""
Gestion des requ√™tes utilisateur pour OBY-IA (d√©tection d‚Äôintention, confirmation et ex√©cution).

Ce module centralise la logique conversationnelle ¬´ back-end ¬ª entre l‚Äôinterface
et les pipelines m√©tier d‚ÄôOBY-IA. Il orchestre deux √©tapes cl√©s :

1) handle_initial_request(...) :
   - Analyse l‚Äôinput utilisateur (d√©tection d‚Äôintention et extraction √©ventuelle
     du nom de patient).
   - Met en place un √©tat de confirmation (session["intent_confirmation_pending"] = True)
     et pr√©pare un message de confirmation.
   - Retourne les √©l√©ments n√©cessaires pour l‚Äôaffichage / la r√©ponse (historique,
     tableaux, graphiques, etc.), g√©n√©ralement vides √† ce stade.

2) handle_confirmation_response(...) :
   - Interpr√®te la confirmation (ex.: ¬´ oui / non ¬ª) lorsque l‚Äôintention est en attente.
   - D√©clenche le pipeline adapt√© :
       ‚Ä¢ PPA (generate_ppa_from_poa.process_ppa_request),
       ‚Ä¢ Recommandations (generate_structured_medical_plan),
       ‚Ä¢ Constantes patient (process_patient_request_with_constants).
   - Met √† jour l‚Äô√©tat de session (r√©initialisation du flag de confirmation,
     m√©morisation du patient courant, etc.) et assemble la r√©ponse finale.

Modes de sortie :
    Le param√®tre `output_mode` permet d‚Äôadapter le format des objets retourn√©s :
      - "dash" : le module peut retourner des composants Dash (html.Div, dcc.Markdown,
                 figures Plotly ¬´ go.Figure ¬ª, etc.) pour l‚ÄôUI interne.
      - "api"  : le module retourne des structures s√©rialisables (listes/dicts/strings),
                 adapt√©es √† FastAPI / JSON (pas d‚Äôobjets Dash).

Effets de bord :
    - Mise √† jour de la session (ex. intent_confirmation_pending, intent_candidate).
    - Enrichissement de l‚Äôhistorique de conversation (chat_history / new_chat_history).

D√©pendances principales :
    - src.llm_user_session.session_manager_instance
    - src.func.extract_user_intent, src.func.extract_patient_name
    - src.func.generate_ppa_from_poa, src.func.generate_structured_medical_plan
    - src.func.get_patient_constants_graphs
    - src.func.serialize_figs (s√©rialisation des figures)
    - (optionnel c√¥t√© UI) dash.html / dash.dcc pour le mode "dash"

Convention de retour :
    Les fonctions retournent un 7-uplet :
        (chat_history_ou_new_chat_history,
         figures_out,
         table_html,
         anomaly_block,
         current_patient,
         serialized_figs,
         chat_history_display)

    * En mode "initial", chat_history est renvoy√© (nouvel historique cumul√©).
    * En mode "confirmation", new_chat_history est renvoy√© (ajouts du tour courant).
    * Le ¬´ full_chat_history ¬ª est assembl√© par l‚Äôappelant si n√©cessaire.

Ce module est con√ßu pour √™tre appel√© √† la fois par l‚Äôinterface Dash (UI)
et par la couche API (FastAPI) via une fonction ¬´ tronc commun ¬ª.
"""


import dash
from dash import dcc, html, callback, ctx, no_update
from typing import Literal

from src.llm_user_session.session_manager_instance import session_manager_instance
from src.func.generate_ppa_from_poa import process_ppa_request
from src.func.generate_structured_medical_plan import generate_structured_medical_plan
from src.func.llm_prompts import system_prompt, system_prompt_medical_plan
from src.func.extract_user_intent import detect_user_intent
from src.func.get_patient_constants_graphs import process_patient_request_with_constants
from src.func.extract_patient_name import extract_patient_name_llm
from src.func.serialize_figs import serialize_figs, deserialize_figs


# ================================================================================================ #
# --------------------- Fonctions accessoires --------------------- #
# ================================================================================================ #
from pathlib import Path
import re

def _normalize_key(s: str | None) -> str:
    s = (s or "").strip().upper()
    s = re.sub(r"\s+", "_", s)
    return s or "UNKNOWN"

def get_patient_key(nom: str | None = None, current_patient: str | None = None, patient_file_path: str | None = None) -> str:
    # Si on conna√Æt d√©j√† le fichier patient, on utilise cette cl√©
    if patient_file_path:
        try:
            return Path(patient_file_path).stem
        except Exception:
            pass
    # Sinon on normalise le nom d√©tect√© / patient courant
    return _normalize_key(nom or current_patient)

def tag_user_div(text: str, patient_key: str, user_id: str, msg_type: str):
    return html.Div(
        text,
        className="user-message",
        id={"type": "chat-msg", "patient_key": patient_key, "user_id": user_id, "msg_type": msg_type},
    )

def tag_bot_div_markdown(md_text: str, patient_key: str, user_id: str, msg_type: str):
    return html.Div(
        dcc.Markdown(md_text),
        className="bot-response",
        id={"type": "chat-msg", "patient_key": patient_key, "user_id": user_id, "msg_type": msg_type},
    )

def filter_history_by_patient_and_user(history: list, patient_key: str, user_id: str) -> list:
    kept = []
    for m in history:
        # dict API
        if isinstance(m, dict) and "props" not in m:
            if m.get("patient_key") == patient_key and m.get("user_id") == user_id:
                kept.append(m)
            continue
        # dict Dash s√©rialis√©
        if isinstance(m, dict) and "props" in m:
            pid = m["props"].get("id", {})
            if isinstance(pid, dict) and pid.get("patient_key") == patient_key and pid.get("user_id") == user_id:
                kept.append(m)
            continue
        # objet Dash
        pid = getattr(m, "id", None)
        if isinstance(pid, dict) and pid.get("patient_key") == patient_key and pid.get("user_id") == user_id:
            kept.append(m)
    return kept

def retag_last_turn_by_type(prev_history: list, final_patient_key: str) -> None:
    """
    Retag la derni√®re confirm_prompt et la user_request qui la pr√©c√®de
    pour leur mettre patient_key = final_patient_key.
    """
    idx_confirm = None
    # trouver la derni√®re confirm_prompt
    for i in range(len(prev_history) - 1, -1, -1):
        _, _, mt = _extract_role_text_type(prev_history[i])
        if mt == "confirm_prompt":
            idx_confirm = i
            break
    if idx_confirm is None:
        return

    def _set_key(m):
        # dict API
        if isinstance(m, dict) and "props" not in m:
            m["patient_key"] = final_patient_key
            return
        # dict Dash s√©rialis√©
        if isinstance(m, dict) and "props" in m:
            pid = m["props"].get("id")
            if isinstance(pid, dict):
                pid["patient_key"] = final_patient_key
            return
        # objet Dash
        pid = getattr(m, "id", None)
        if isinstance(pid, dict):
            pid["patient_key"] = final_patient_key

    _set_key(prev_history[idx_confirm])          # confirm_prompt
    if idx_confirm - 1 >= 0:
        _set_key(prev_history[idx_confirm - 1])  # user_request

def keep_last_request_plus_confirm(history_filtered: list) -> list:
    idx_confirm = None
    for i in range(len(history_filtered) - 1, -1, -1):
        _, _, mt = _extract_role_text_type(history_filtered[i])
        if mt == "confirm_prompt":
            idx_confirm = i
            break
    if idx_confirm is None:
        return history_filtered
    start = idx_confirm - 1
    for j in range(idx_confirm - 1, -1, -1):
        _, _, mt = _extract_role_text_type(history_filtered[j])
        if mt == "user_request":
            start = j
            break
    return history_filtered[max(start, 0): idx_confirm + 1]

def _extract_role_text_type(msg):
    """
    Retourne (role, text, msg_type) pour:
      - dict API: {'role', 'text'/'markdown', 'msg_type'}
      - dict Dash s√©rialis√©: {'type','namespace','props':{id, className, children}}
      - objet Dash (html.Div/dcc.Markdown) en m√©moire
    """
    # 1) dict API
    if isinstance(msg, dict) and "props" not in msg and ("role" in msg or "msg_type" in msg):
        role = msg.get("role")
        text = (msg.get("markdown") or msg.get("text") or "")
        mtyp = msg.get("msg_type")
        return role, str(text), mtyp

    # 2) dict Dash s√©rialis√© (venant du dcc.Store)
    if isinstance(msg, dict) and "props" in msg:
        props = msg.get("props", {}) or {}
        className = props.get("className", "") or ""
        role = "assistant" if "bot-response" in className else ("user" if "user-message" in className else None)

        pid = props.get("id", {})
        mtyp = pid.get("msg_type") if isinstance(pid, dict) else None

        ch = props.get("children", None)
        # dcc.Markdown s√©rialis√© -> {'type':'Markdown','props':{'children': '...'}}
        if isinstance(ch, dict) and "props" in ch:
            text = ch["props"].get("children", "")
        # parfois children peut √™tre une liste (Dash s√©rialise des tableaux)
        elif isinstance(ch, list):
            # concat simple des fragments textuels
            text = " ".join(str(x) for x in ch if isinstance(x, (str, int, float)))
        else:
            text = ch if isinstance(ch, (str, int, float)) or ch is None else ""

        return role, str(text or ""), mtyp

    # 3) objet Dash (runtime)
    cls = getattr(msg, "className", "") or ""
    role = "assistant" if "bot-response" in cls else ("user" if "user-message" in cls else None)
    pid = getattr(msg, "id", None)
    mtyp = pid.get("msg_type") if isinstance(pid, dict) else None
    ch = getattr(msg, "children", None)
    if hasattr(ch, "children"):
        text = ch.children if ch.children is not None else ""
    else:
        text = ch if ch is not None else ""
    return role, str(text), mtyp

# Wrapper pour le code existant qui appelle encore _extract_role_and_text
def _extract_role_and_text(msg):
    role, text, _ = _extract_role_text_type(msg)
    return role, text

def _types(lst):
    return [_extract_role_text_type(m)[2] for m in (lst[-4:] if lst else [])]

def trim_to_last_confirmation_block(history: list) -> list:
    idx_confirm = None
    for i in range(len(history) - 1, -1, -1):
        role, text, mt = _extract_role_text_type(history[i])
        if mt == "confirm_prompt" or (role == "assistant" and "confirmez" in text.lower()):
            idx_confirm = i
            break
    if idx_confirm is None:
        return history
    start = idx_confirm - 1
    for j in range(idx_confirm - 1, -1, -1):
        r, _, mt = _extract_role_text_type(history[j])
        if mt == "user_request" or r == "user":
            start = j
            break
    return history[max(start, 0):]


# ================================================================================================ #
# --------------------- Fonctions appel√©es par handle_user_input_or_logout() --------------------- #
# ================================================================================================ #
# 1/.
def handle_initial_request(user_input, session,
                           session_data, chat_history,
                           current_patient, output_mode: Literal["dash", "api"] = "dash"):

    """
    Traite la requ√™te initiale : d√©tection d‚Äôintention et demande de confirmation.

    Cette fonction :
      1. D√©tecte l‚Äôintention de l‚Äôutilisateur (ex. generate_ppa, get_constants,
         get_recommendations) et tente d‚Äôidentifier le patient mentionn√©.
      2. Met √† jour la session pour indiquer qu‚Äôune confirmation est requise :
         - session["intent_confirmation_pending"] = True
         - session["intent_candidate"] = {"intent": <str>, "name": <str|None>, "full_user_input": <str>}
      3. Construit et ajoute au fil de conversation un message de confirmation
         (¬´ Je comprends que vous souhaitez‚Ä¶ confirmez-vous oui/non ? ¬ª).

    Param√®tres
    ----------
    user_input : str
        Texte brut saisi par l‚Äôutilisateur.
    session : dict
        Objet de session r√©cup√©r√© via `session_manager_instance.get_session(...)`.
    session_data : dict
        Donn√©es de session de l‚ÄôUI (ex. {"user_id": ..., "session_id": ...}).
    chat_history : list
        Historique courant de la conversation (format d√©pendant de `output_mode`).
    current_patient : str | None
        Patient courant, si d√©j√† connu.
    output_mode : {"dash", "api"}, optionnel
        Mode de sortie. "dash" peut retourner des composants Dash ;
        "api" ne retourne que des structures JSON-s√©rialisables.

    Retours
    -------
    tuple
        Un 7-uplet :
            chat_history : list
                Historique mis √† jour (int√©grant le message de confirmation).
            figures_out : list
                Liste de figures (souvent vide √† ce stade).
            table_html : str
                Table HTML (souvent vide √† ce stade).
            anomaly_block : str
                Bloc d‚Äôanomalies (souvent vide √† ce stade).
            current_patient : str | None
                Patient d√©tect√© ou patient courant.
            serialized_figs : list | None
                Figures s√©rialis√©es (si `output_mode="dash"` et si pr√©sent).
            chat_history_display : Any
                Repr√©sentation pr√™te √† l‚Äôaffichage (UI), inutilis√©e en mode API.

    Notes
    -----
    - Aucun pipeline m√©tier n‚Äôest ex√©cut√© √† ce stade : la fonction se limite
      √† pr√©parer la confirmation d‚Äôintention.
    - L‚Äôappelant est responsable d‚Äôafficher `chat_history` et d‚Äôattendre la
      r√©ponse de confirmation de l‚Äôutilisateur.
    """

    # --- IDs fournis par l‚ÄôUI ---
    user_id = (session_data or {}).get("user_id")
    session_id = (session_data or {}).get("session_id")
    if not user_id or not session_id:
        raise ValueError("session_data manquant: 'user_id' et/ou 'session_id'")

    # --- R√©cup√©rer/Cr√©er la session c√¥t√© serveur ---
    server_session = session_manager_instance.get_session(session_id)
    if server_session is None:
        session_manager_instance.create_session(user_id=user_id, session_id=session_id)
        server_session = session_manager_instance.get_session(session_id)

    # --- (Option) coh√©rence user_id ---
    if server_session.get("user_id") != user_id:
        user_id = server_session.get("user_id")

    # --- On retourne un DELTA uniquement ---
    chat_history = []

    # --- Logs & d√©tection ---
    bot_response = None  # on n‚Äôappendra qu‚Äôun SEUL confirm_prompt plus bas
    print("üöÄ handle_initial_request()")
    print(f'üü° requ√™te utilisateur {user_input}')

    intent_dict = detect_user_intent(user_input)
    nom = extract_patient_name_llm(user_input)
    intent = intent_dict.get("intent", "unknown")
    print(f'üü¢ Intention d√©tect√©e: {intent}')

    # --- Tag du message utilisateur ---
    nom_norm = (nom or "").strip()
    candidate_key = get_patient_key(nom=nom_norm, current_patient=current_patient)

    # 1) REQU√äTE (user)
    if output_mode == "dash":
        chat_history.append(
            tag_user_div(f"üë§ {user_input.strip()}", candidate_key, user_id, "user_request")
        )
    else:
        chat_history.append({
            "role": "user",
            "text": user_input.strip(),
            "patient_key": candidate_key,
            "user_id": user_id,
            "msg_type": "user_request",
        })

    # 2) Construire le TEXTE FINAL de confirmation (une seule fois)
    if intent == "generate_ppa":
        text = "demande de g√©n√©ration de PPA"
        confirm_text = f"Je comprends que vous souhaitez une {text}, est-ce que vous confirmez oui/non ?"
    elif intent == "get_constants":
        text = "demande de constantes patient"
        confirm_text = f"Je comprends que vous souhaitez une {text}, est-ce que vous confirmez oui/non ?"
    elif intent == "generate_recommendations":
        text = "demande de recommandations de soins"
        confirm_text = f"Je comprends que vous souhaitez une {text}, est-ce que vous confirmez oui/non ?"
    else:
        confirm_text = (
            "‚ùå Cette demande ne peut pas √™tre trait√©e par OBY-IA, car elle sort du cadre de l'accompagnement des personnes √¢g√©es.\n\n"
            "Voici quelques exemples de requ√™tes que vous pouvez utiliser :\n"
            "- *Pr√©pare-moi le plan d‚Äôaide pour Madame Dupont*\n"
            "- *Montre-moi les constantes du patient Martin sur le dernier mois*\n"
            "- *Quelles sont les recommandations en cas d‚ÄôAVC ?*"
        )

    # 3) DEMANDE DE CONFIRMATION (assistant) ‚Äî une seule insertion
    if output_mode == "dash":
        chat_history.append(
            tag_bot_div_markdown(confirm_text, candidate_key, user_id, "confirm_prompt")
        )
    else:
        chat_history.append({
            "role": "assistant",
            "markdown": str(confirm_text),
            "patient_key": candidate_key,
            "user_id": user_id,
            "msg_type": "confirm_prompt",
        })

    # 4) Marquer la session (√©criture IN-PLACE dans le dict du manager)
    server_session["intent_confirmation_pending"] = True
    server_session["intent_candidate"] = {
        "intent": intent,
        "name": nom_norm,
        "full_user_input": user_input,
    }

    # 5) (Option) historiser dans l‚Äôobjet Session si tu l‚Äôutilises
    sess_obj = server_session.get("session_obj")
    if sess_obj:
        sess_obj.add_message(user_input, confirm_text)

    chat_history_display = None

    types = [_extract_role_text_type(m)[2] for m in chat_history]
    print(f"üü† chat_history juste avant return (len={len(chat_history)}): types={types}")

    return chat_history, [], "", "", current_patient, [], chat_history_display


# 2/.
def handle_confirmation_response(user_input, session,
                                 session_data, chat_history,
                                 current_patient, output_mode: Literal["dash", "api"] = "dash"):

    """
    Traite la r√©ponse de confirmation et ex√©cute le pipeline m√©tier appropri√©.

    Cette fonction :
      1. Lit l‚Äô√©tat `session["intent_candidate"]` d√©fini lors de la requ√™te initiale,
         ainsi que la confirmation utilisateur (ex. ¬´ oui ¬ª, ¬´ non ¬ª).
      2. En cas de confirmation :
         - Ex√©cute le pipeline adapt√© selon l‚Äôintention d√©tect√©e :
             * generate_ppa  ‚Üí process_ppa_request(...)
             * get_constants ‚Üí process_patient_request_with_constants(...)
             * get_recommendations ‚Üí generate_structured_medical_plan(...)
         - Met √† jour l‚Äôhistorique avec la r√©ponse ¬´ bot ¬ª, les tableaux/figures,
           et s√©rialise les figures si n√©cessaire (mode "dash").
         - R√©initialise l‚Äô√©tat de confirmation dans la session.
      3. En cas de refus :
         - R√©initialise l‚Äô√©tat de confirmation.
         - Ajoute un message d‚Äôaide avec des exemples de requ√™tes valides.

    Param√®tres
    ----------
    user_input : str
        Texte brut saisi par l‚Äôutilisateur (confirmation et/ou compl√©ments).
    session : dict
        Objet de session r√©cup√©r√© via `session_manager_instance.get_session(...)`.
    session_data : dict
        Donn√©es de session de l‚ÄôUI (ex. {"user_id": ..., "session_id": ...}).
    chat_history : list
        Historique de conversation avant ce tour (format d√©pendant de `output_mode`).
    current_patient : str | None
        Patient courant, si d√©j√† connu.
    output_mode : {"dash", "api"}, optionnel
        Mode de sortie. "dash" peut retourner des composants Dash ;
        "api" ne retourne que des structures JSON-s√©rialisables.

    Retours
    -------
    tuple
        Un 7-uplet :
            new_chat_history : list
                Messages ajout√©s sur ce tour (√† concat√©ner par l‚Äôappelant).
            figures_out : list
                Figures produites (listes de go.Figure en "dash", ou dict Plotly en "api").
            table_html : str
                Tableau HTML des constantes (si pertinent).
            anomaly_block : str
                Bloc d‚Äôanomalies (si pertinent).
            current_patient : str | None
                Patient courant (√©ventuellement mis √† jour).
            serialized_figs : list | None
                Figures s√©rialis√©es (utiles au stockage / export en mode UI).
            chat_history_display : Any
                Repr√©sentation pr√™te √† l‚Äôaffichage (UI), inutilis√©e en mode API.

    Exceptions
    ----------
    Peut lever des exceptions m√©tiers/FS sous-jacentes (lecture des donn√©es,
    g√©n√©ration de graphique, etc.) qui doivent √™tre g√©r√©es par l‚Äôappelant
    (selon le contexte UI ou API).

    Remarques
    ---------
    - L‚Äôappelant est responsable de former le `full_chat_history` en concat√©nant
      `chat_history + new_chat_history`.
    - La fonction remet √† plat les drapeaux de confirmation dans `session`.
    """

    figs_list: list = []
    table_html = ""
    anomaly_block = ""
    serialized_figs = None
    figures_out: list = []
    bot_response: str = ""
    session_id = session_data["session_id"]

    # --- IDs fournis par l‚ÄôUI ---
    user_id = (session_data or {}).get("user_id")
    session_id = (session_data or {}).get("session_id")
    if not user_id or not session_id:
        raise ValueError("session_data manquant: 'user_id' et/ou 'session_id'")

    # --- R√©cup√©rer/Cr√©er la session c√¥t√© serveur ---
    server_session = session_manager_instance.get_session(session_id)
    if server_session is None:
        session_manager_instance.create_session(user_id=user_id, session_id=session_id)
        server_session = session_manager_instance.get_session(session_id)

    # --- Etat historique complet avant reset pour delta ---
    prev_chat_history = list(chat_history) if chat_history else []

    # chat_history = delta des √©changes
    chat_history = []

    # =======Debug: V√©rification: ce que contient chat_history ===========
    # print(
    #     "üü† prev_chat_history --Fn handle_conf_req-- len=", len(prev_chat_history),
    #     "tail types=",
    #     [_extract_role_text_type(m)[2] for m in (prev_chat_history[-4:] if prev_chat_history else [])]
    # )

    types = [_extract_role_text_type(m)[2] for m in prev_chat_history]
    print(f"üü† prev_chat_history len={len(prev_chat_history)} types_tail={types[-4:]}")

    ok_pair = len(prev_chat_history) >= 2 and types[-2:] == ["user_request", "confirm_prompt"]

    if ok_pair:
        # (optionnel) log court des deux textes
        tu = _extract_role_text_type(prev_chat_history[-2])[1][:80].replace("\n", " ")
        ta = _extract_role_text_type(prev_chat_history[-1])[1][:80].replace("\n", " ")
        print(f"‚úÖ paire OK -> user_request: {tu} | confirm_prompt: {ta}")
    else:
        print("üî¥Ô∏è paire absente -> pas de user_request+confirm_prompt")

    # =================================================================================


    # Mise en place tag "switched" -> adapter texte affich√© si changement patient
    filtered_prev_for_display: list = []
    chat_history_display: list | None = None
    switched = False

    # Initialisaiton
    intent_candidate = session.get("intent_candidate") or {}
    candidate_name = intent_candidate.get("name")

    # Initialisaiton patient_key
    patient_key = get_patient_key(
        nom=candidate_name or current_patient,
        current_patient=current_patient,
        patient_file_path=None
    )

    # Retag + filtre
    retag_last_turn_by_type(prev_chat_history, patient_key)
    filtered_prev_for_display = filter_history_by_patient_and_user(prev_chat_history, patient_key, user_id)
    print("üü† filtered types=", _types(filtered_prev_for_display))


    # R√©cup√©ration r√©ponse utilisateur
    print('‚ö†Ô∏èConfirmation attendue...')
    answer = user_input.strip().lower()
    dash_yes_text = f"üë§ {answer}"
    api_yes_text = user_input.strip()

    # server_session["intent_confirmation_pending"]

    full_user_input = server_session["intent_candidate"]["full_user_input"]
    # print(f'‚ö†Ô∏èhandle_confirmation_response/full_user_input: {full_user_input}')


    # Intention confirm√©e, -> changement √©tat de intent_confirmation_pending
    norm_answer = answer.replace("‚Äô", "'").strip().strip(" .!?,;:")
    if norm_answer in {"oui", "yes", "ok", "o", "y", "c'est bien √ßa"}:
        server_session["intent_confirmation_pending"] = False
        intent = server_session["intent_candidate"]["intent"]
        nom = server_session["intent_candidate"]["name"]

        patient_key = get_patient_key(
            nom=server_session.get("intent_candidate", {}).get("name") or nom or current_patient,
            current_patient=current_patient,
            patient_file_path=None
        )


        # D√©finition des flags
        ppa_requested = intent == "generate_ppa"
        constantes_requested = intent == "get_constants"
        recommandations_requested = intent == "generate_recommendations"
        print(f"‚úÖ Intention confirm√©e par l‚Äôutilisateur : {intent}")

        print(f"üéØ Intentions d√©tect√©es : "
              f"recommandations: {recommandations_requested},"
              f"constantes={constantes_requested}, "
              f"ppa={ppa_requested}, "
              f"nom patient={nom}")
        print(f'‚úÖd√©tection intention r√©ussie')


        # On d√©clenche l'un des pipelines suivants selon l'intention d√©tect√©e
        # --- R√©initialisation si changement de patient ---
        if nom and (ppa_requested or constantes_requested or recommandations_requested):
            if nom != current_patient:
                print(f"üî¥ Changement de patient d√©tect√© : {current_patient} ‚û°Ô∏è {nom}")
                switched = True

                # harmoniser le DERNIER couple vers la cl√© FINALE du patient
                retag_last_turn_by_type(prev_chat_history, patient_key)

                # filtrer le snapshot par patient+user
                filtered_prev_for_display = filter_history_by_patient_and_user(prev_chat_history, patient_key, user_id)
                print("‚úÖ filtered_prev_for_display:",
                      [(_extract_role_text_type(m)[2]) for m in filtered_prev_for_display])
                # attendu: ["user_request", "confirm_prompt"]

                # ne garder QUE le dernier couple [user_request, confirm_prompt]
                filtered_prev_for_display = keep_last_request_plus_confirm(filtered_prev_for_display)

                # ajouter le "oui" (delta), tagu√©
                if output_mode == "dash":
                    chat_history.append(tag_user_div(f"üë§ {answer}", patient_key, user_id, "confirm_answer"))
                else:
                    chat_history.append({"role": "user", "text": user_input.strip(),
                                         "patient_key": patient_key, "user_id": user_id, "msg_type": "confirm_answer"})


                # Reset UI de l‚Äôancien patient + MAJ √©tat
                figs_list = []
                table_html = ""
                anomaly_block = ""
                current_patient = nom
                session_manager_instance.reset_anonymization_mapping(user_id)
                session_manager_instance.set_current_patient(session_id, nom)

            else:
                print(f"‚úÖ Patient conserv√© : {current_patient}")
                answer_raw = (user_input or "").strip()
                dash_yes_text = f"üë§ {answer_raw}"
                if output_mode == "dash":
                    user_msg = tag_user_div(dash_yes_text, patient_key, user_id, "confirm_answer")
                else:
                    user_msg = {
                        "role": "user",
                        "text": answer_raw,
                        "patient_key": patient_key,
                        "user_id": user_id,
                        "msg_type": "confirm_answer",
                    }

                chat_history.append(user_msg)

        # --- Traitement des constantes ---
        if constantes_requested:
            try:
                print("‚úÖ Appel √† process_patient_request_with_constants()")
                bot_response, figs_list, table_html, anomaly_block = process_patient_request_with_constants(nom)

                if output_mode == "dash":
                    # ‚úÖ Mode UI Dash: s√©rialisation pour dcc.Store
                    serialized_figs = serialize_figs(figs_list)
                    figures_out = figs_list  # pour construire dcc.Graph c√¥t√© callback
                else:
                    # ‚úÖ Mode API: JSON Plotly directement exploitable c√¥t√© OBY
                    figures_out = [fig.to_plotly_json() for fig in figs_list]
                    serialized_figs = None

            except Exception as e:
                print(f"‚ùå Erreur dans process_patient_request_with_constants : {e}")
                bot_response = "Une erreur est survenue pendant le traitement des constantes."
                figs_list, table_html, anomaly_block = [], "", ""


                # --- Traitement demande PPA ---
        elif ppa_requested:
            print("‚úÖ Appel √† process_ppa_request() pour le PPA")
            try:
                bot_response, dict_mapping = process_ppa_request(full_user_input, system_prompt)

                # Enregistrer le mapping renvoy√© par la fonction dans la session
                # Le r√©cup√©rer proprement via session_manager.get_anonymization_mapping()
                session_manager_instance.set_anonymization_mapping(session_id, dict_mapping)

                # Quand le LLM a donn√© une r√©ponse (bot_response), ajout de la r√©ponse dans la session
                session_manager_instance.append_llm_response(session_id, bot_response)

                # ‚úÖ Ajout √©change complet (question + r√©ponse)
                session = session_manager_instance.get_session(session_id)
                session_obj = session.get("session_obj")
                if session_obj:
                    session_obj.add_message(user_input, bot_response)

                figs_list, table_html, anomaly_block = [], "", ""

            except Exception as e:
                print(f"‚ùå Erreur dans process_ppa_request : {e}")
                bot_response = "Une erreur est survenue pendant la g√©n√©ration du PPA."
                figs_list, table_html, anomaly_block = [], "", ""


        # --- Traitement demande plan de soins ---
        elif recommandations_requested:
            print("‚úÖ Appel √† generate_structured_medical_plan() pour plan de soins")
            try:
                bot_response, dict_mapping = generate_structured_medical_plan(full_user_input,
                                                                              system_prompt_medical_plan)

                # Enregistrer le mapping renvoy√© par la fonction dans la session
                # Le r√©cup√©rer proprement via session_manager.get_anonymization_mapping()
                session_manager_instance.set_anonymization_mapping(session_id, dict_mapping)

                # Quand le LLM a donn√© une r√©ponse (bot_response), ajout de la r√©ponse dans la session
                print("üî¥before -> session_manager_instance.append_llm_response(session_id, bot_response")
                session_manager_instance.append_llm_response(session_id, bot_response)
                print("üî¥after -> session_manager_instance.append_llm_response(session_id, bot_response")

                # ‚úÖ Ajouter l‚Äô√©change complet (question + r√©ponse)
                print("üî¥before -> session_manager_instance.get_session(session_id)")
                session = session_manager_instance.get_session(session_id)
                print("üî¥after -> session_manager_instance.get_session(session_id)")
                session_obj = session.get("session_obj")
                if session_obj:
                    print("üî¥before -> session_obj.add_message(user_input, bot_response)")
                    session_obj.add_message(user_input, bot_response)
                    print("üî¥after -> session_obj.add_message(user_input, bot_response)")

                figs_list, table_html, anomaly_block = [], "", ""

            except Exception as e:
                print(f"‚ùå Erreur dans generate_structured_medical_plan : {e}")
                bot_response = "Une erreur est survenue pendant l'extraction des recommandations de soins."
                figs_list, table_html, anomaly_block = [], "", ""



    else:
        # Rejet de l‚Äôintention
        session["intent_confirmation_pending"] = False
        session["intent_candidate"] = {"intent": None, "name": None, "full_user_input": ""}

        bot_response = (
            "Compris. Voici quelques exemples de requ√™tes que vous pouvez utiliser :\n"
            "- *Pr√©pare-moi le plan d‚Äôaide pour Madame Dupont*\n"
            "- *Montre-moi les constantes du patient Martin sur le dernier mois*\n"
            "- *Quelles sont les recommandations en cas d‚ÄôAVC ?*"
        )

    if bot_response:
        if output_mode == "dash":
            chat_history.append(tag_bot_div_markdown(str(bot_response), patient_key, user_id, "bot_response"))
        else:
            chat_history.append({
                "role": "assistant",
                "markdown": str(bot_response),
                "patient_key": patient_key,
                "user_id": user_id,
                "msg_type": "bot_response",
            })


    if switched:
        chat_history_display = filtered_prev_for_display + chat_history
    else:
        chat_history_display = None

    print("‚úÖ delta types:",
          [(_extract_role_text_type(m)[2]) for m in chat_history])
    # attendu: ["confirm_answer", "bot_response"] (si le bot a r√©pondu)

    return (chat_history, figures_out, table_html,
            anomaly_block, current_patient,
            serialized_figs, chat_history_display)
