"""
Gestion des requÃªtes utilisateur pour OBY-IA (dÃ©tection dâ€™intention, confirmation et exÃ©cution).

Ce module centralise la logique conversationnelle Â« back-end Â» entre lâ€™interface
et les pipelines mÃ©tier dâ€™OBY-IA. Il orchestre deux Ã©tapes clÃ©s :

1) handle_initial_request(...) :
   - Analyse lâ€™input utilisateur (dÃ©tection dâ€™intention et extraction Ã©ventuelle
     du nom de patient).
   - Met en place un Ã©tat de confirmation (session["intent_confirmation_pending"] = True)
     et prÃ©pare un message de confirmation.
   - Retourne les Ã©lÃ©ments nÃ©cessaires pour lâ€™affichage / la rÃ©ponse (historique,
     tableaux, graphiques, etc.), gÃ©nÃ©ralement vides Ã  ce stade.

2) handle_confirmation_response(...) :
   - InterprÃ¨te la confirmation (ex.: Â« oui / non Â») lorsque lâ€™intention est en attente.
   - DÃ©clenche le pipeline adaptÃ© :
       â€¢ PPA (generate_ppa_from_poa.process_ppa_request),
       â€¢ Recommandations (generate_structured_medical_plan),
       â€¢ Constantes patient (process_patient_request_with_constants).
   - Met Ã  jour lâ€™Ã©tat de session (rÃ©initialisation du flag de confirmation,
     mÃ©morisation du patient courant, etc.) et assemble la rÃ©ponse finale.

Modes de sortie :
    Le paramÃ¨tre `output_mode` permet dâ€™adapter le format des objets retournÃ©s :
      - "dash" : le module peut retourner des composants Dash (html.Div, dcc.Markdown,
                 figures Plotly Â« go.Figure Â», etc.) pour lâ€™UI interne.
      - "api"  : le module retourne des structures sÃ©rialisables (listes/dicts/strings),
                 adaptÃ©es Ã  FastAPI / JSON (pas dâ€™objets Dash).

Effets de bord :
    - Mise Ã  jour de la session (ex. intent_confirmation_pending, intent_candidate).
    - Enrichissement de lâ€™historique de conversation (chat_history / new_chat_history).

DÃ©pendances principales :
    - src.llm_user_session.session_manager_instance
    - src.func.extract_user_intent, src.func.extract_patient_name
    - src.func.generate_ppa_from_poa, src.func.generate_structured_medical_plan
    - src.func.get_patient_constants_graphs
    - src.func.serialize_figs (sÃ©rialisation des figures)
    - (optionnel cÃ´tÃ© UI) dash.html / dash.dcc pour le mode "dash"

Convention de retour :
    Les fonctions retournent un 7-uplet :
        (chat_history_ou_new_chat_history,
         figures_out,
         table_html,
         anomaly_block,
         current_patient,
         serialized_figs,
         chat_history_display)

    * En mode "initial", chat_history est renvoyÃ© (nouvel historique cumulÃ©).
    * En mode "confirmation", new_chat_history est renvoyÃ© (ajouts du tour courant).
    * Le Â« full_chat_history Â» est assemblÃ© par lâ€™appelant si nÃ©cessaire.

Ce module est conÃ§u pour Ãªtre appelÃ© Ã  la fois par lâ€™interface Dash (UI)
et par la couche API (FastAPI) via une fonction Â« tronc commun Â».
"""


import dash
from dash import dcc, html, callback, ctx, no_update
from typing import Literal

from src.llm_user_session.session_manager_instance import session_manager_instance
from src.func.generate_ppa_from_poa import process_ppa_request
from src.func.generate_structured_medical_plan import generate_structured_medical_plan
from src.func.llm_prompts import system_prompt, system_prompt_medical_plan
from src.func.extract_user_intent import detect_user_intent
from src.func.get_patient_constants_graphs import process_patient_request_with_constants
from src.func.extract_patient_name import extract_patient_name_llm
from src.func.serialize_figs import serialize_figs, deserialize_figs




# ================================================================================================ #
# --------------------- Fonctions appelÃ©es par handle_user_input_or_logout() --------------------- #
# ================================================================================================ #
# 1/.
def handle_initial_request(user_input, session,
                           session_data, chat_history,
                           current_patient, output_mode: Literal["dash", "api"] = "dash"):

    """
    Traite la requÃªte initiale : dÃ©tection dâ€™intention et demande de confirmation.

    Cette fonction :
      1. DÃ©tecte lâ€™intention de lâ€™utilisateur (ex. generate_ppa, get_constants,
         get_recommendations) et tente dâ€™identifier le patient mentionnÃ©.
      2. Met Ã  jour la session pour indiquer quâ€™une confirmation est requise :
         - session["intent_confirmation_pending"] = True
         - session["intent_candidate"] = {"intent": <str>, "name": <str|None>, "full_user_input": <str>}
      3. Construit et ajoute au fil de conversation un message de confirmation
         (Â« Je comprends que vous souhaitezâ€¦ confirmez-vous oui/non ? Â»).

    ParamÃ¨tres
    ----------
    user_input : str
        Texte brut saisi par lâ€™utilisateur.
    session : dict
        Objet de session rÃ©cupÃ©rÃ© via `session_manager_instance.get_session(...)`.
    session_data : dict
        DonnÃ©es de session de lâ€™UI (ex. {"user_id": ..., "session_id": ...}).
    chat_history : list
        Historique courant de la conversation (format dÃ©pendant de `output_mode`).
    current_patient : str | None
        Patient courant, si dÃ©jÃ  connu.
    output_mode : {"dash", "api"}, optionnel
        Mode de sortie. "dash" peut retourner des composants Dash ;
        "api" ne retourne que des structures JSON-sÃ©rialisables.

    Retours
    -------
    tuple
        Un 7-uplet :
            chat_history : list
                Historique mis Ã  jour (intÃ©grant le message de confirmation).
            figures_out : list
                Liste de figures (souvent vide Ã  ce stade).
            table_html : str
                Table HTML (souvent vide Ã  ce stade).
            anomaly_block : str
                Bloc dâ€™anomalies (souvent vide Ã  ce stade).
            current_patient : str | None
                Patient dÃ©tectÃ© ou patient courant.
            serialized_figs : list | None
                Figures sÃ©rialisÃ©es (si `output_mode="dash"` et si prÃ©sent).
            chat_history_display : Any
                ReprÃ©sentation prÃªte Ã  lâ€™affichage (UI), inutilisÃ©e en mode API.

    Notes
    -----
    - Aucun pipeline mÃ©tier nâ€™est exÃ©cutÃ© Ã  ce stade : la fonction se limite
      Ã  prÃ©parer la confirmation dâ€™intention.
    - Lâ€™appelant est responsable dâ€™afficher `chat_history` et dâ€™attendre la
      rÃ©ponse de confirmation de lâ€™utilisateur.
    """
    chat_history = []
    # --- Si une demande utlisateur existe ---

    bot_response = "ğŸ¤– Je traite votre demande..."
    print("ğŸš€ chatbot_ui.py chargÃ© !")
    print(f'ğŸŸ¡ requÃªte utilisateur {user_input}')

    # DÃ©tection intention
    intent_dict = detect_user_intent(user_input)
    nom = extract_patient_name_llm(user_input)
    intent = intent_dict.get("intent", "unknown")
    print(f'ğŸŸ¢Intention dÃ©tectÃ©e: {intent}')

    # --- Affichage requÃªte + concatÃ©nation chat_history ---
    if output_mode == "dash":
        user_msg = html.Div(f"ğŸ‘¤ {user_input.strip()}", className="user-message")
    else:
        user_msg = {"role": "user", "text": user_input.strip()}

    chat_history.append(user_msg)

    # En attente de confirmation par l'utlisateur
    session["intent_confirmation_pending"] = True
    session["intent_candidate"] = {"intent": intent, "name": nom, "full_user_input": user_input}

    # --- Ã‰tape affichage de l'intention ---
    if intent == "generate_ppa":
        text = "demande de gÃ©nÃ©ration de PPA"
        bot_response = f"Je comprends que vous souhaitez une {text}, est-ce que vous confirmez oui/non ?"

    elif intent == "get_constants":
        text = "demande de constantes patient"
        bot_response = f"Je comprends que vous souhaitez une {text}, est-ce que vous confirmez oui/non ?"

    elif intent == "generate_recommendations":
        text = "demande de recommandations de soins"
        bot_response = f"Je comprends que vous souhaitez une {text}, est-ce que vous confirmez oui/non ?"

    else:
        # RequÃªte hors contexte gÃ©rable
        bot_response = (
            "âŒ Cette demande ne peut pas Ãªtre traitÃ©e par OBY-IA, car elle sort du cadre de l'accompagnement des personnes Ã¢gÃ©es.\n\n"
            "Voici quelques exemples de requÃªtes que vous pouvez utiliser :\n"
            "- *PrÃ©pare-moi le plan dâ€™aide pour Madame Dupont*\n"
            "- *Montre-moi les constantes du patient Martin sur le dernier mois*\n"
            "- *Quelles sont les recommandations en cas dâ€™AVC ?*"
        )

    # Logique API ou Dash...
    if output_mode == "dash":
        chat_history.append(html.Div(dcc.Markdown(bot_response), className="bot-response"))
    else:
        # API-safe structure (pure JSON)
        chat_history.append({"role": "assistant", "markdown": str(bot_response)})


    # Enregistrer l'Ã©change (requÃªte utilisateur + demande de confirmation)
    session = session_manager_instance.get_session(session_data["session_id"])
    session_obj = session.get("session_obj")
    if session_obj:
        session_obj.add_message(user_input, bot_response)

    chat_history_display = None

    return chat_history, [], "", "", current_patient, [], chat_history_display



# 2/.
def handle_confirmation_response(user_input, session,
                                 session_data, chat_history,
                                 current_patient, output_mode: Literal["dash", "api"] = "dash"):

    """
    Traite la rÃ©ponse de confirmation et exÃ©cute le pipeline mÃ©tier appropriÃ©.

    Cette fonction :
      1. Lit lâ€™Ã©tat `session["intent_candidate"]` dÃ©fini lors de la requÃªte initiale,
         ainsi que la confirmation utilisateur (ex. Â« oui Â», Â« non Â»).
      2. En cas de confirmation :
         - ExÃ©cute le pipeline adaptÃ© selon lâ€™intention dÃ©tectÃ©e :
             * generate_ppa  â†’ process_ppa_request(...)
             * get_constants â†’ process_patient_request_with_constants(...)
             * get_recommendations â†’ generate_structured_medical_plan(...)
         - Met Ã  jour lâ€™historique avec la rÃ©ponse Â« bot Â», les tableaux/figures,
           et sÃ©rialise les figures si nÃ©cessaire (mode "dash").
         - RÃ©initialise lâ€™Ã©tat de confirmation dans la session.
      3. En cas de refus :
         - RÃ©initialise lâ€™Ã©tat de confirmation.
         - Ajoute un message dâ€™aide avec des exemples de requÃªtes valides.

    ParamÃ¨tres
    ----------
    user_input : str
        Texte brut saisi par lâ€™utilisateur (confirmation et/ou complÃ©ments).
    session : dict
        Objet de session rÃ©cupÃ©rÃ© via `session_manager_instance.get_session(...)`.
    session_data : dict
        DonnÃ©es de session de lâ€™UI (ex. {"user_id": ..., "session_id": ...}).
    chat_history : list
        Historique de conversation avant ce tour (format dÃ©pendant de `output_mode`).
    current_patient : str | None
        Patient courant, si dÃ©jÃ  connu.
    output_mode : {"dash", "api"}, optionnel
        Mode de sortie. "dash" peut retourner des composants Dash ;
        "api" ne retourne que des structures JSON-sÃ©rialisables.

    Retours
    -------
    tuple
        Un 7-uplet :
            new_chat_history : list
                Messages ajoutÃ©s sur ce tour (Ã  concatÃ©ner par lâ€™appelant).
            figures_out : list
                Figures produites (listes de go.Figure en "dash", ou dict Plotly en "api").
            table_html : str
                Tableau HTML des constantes (si pertinent).
            anomaly_block : str
                Bloc dâ€™anomalies (si pertinent).
            current_patient : str | None
                Patient courant (Ã©ventuellement mis Ã  jour).
            serialized_figs : list | None
                Figures sÃ©rialisÃ©es (utiles au stockage / export en mode UI).
            chat_history_display : Any
                ReprÃ©sentation prÃªte Ã  lâ€™affichage (UI), inutilisÃ©e en mode API.

    Exceptions
    ----------
    Peut lever des exceptions mÃ©tiers/FS sous-jacentes (lecture des donnÃ©es,
    gÃ©nÃ©ration de graphique, etc.) qui doivent Ãªtre gÃ©rÃ©es par lâ€™appelant
    (selon le contexte UI ou API).

    Remarques
    ---------
    - Lâ€™appelant est responsable de former le `full_chat_history` en concatÃ©nant
      `chat_history + new_chat_history`.
    - La fonction remet Ã  plat les drapeaux de confirmation dans `session`.
    """

    figs_list: list = []
    table_html = ""
    anomaly_block = ""
    serialized_figs = None
    figures_out: list = []
    bot_response: str = ""
    chat_history = []
    user_id = session_data["user_id"]
    session_id = session_data["session_id"]


    print('âš ï¸Confirmation attendue...')
    answer = user_input.strip().lower()
    print(f"âœ…RÃ©ponse de l'utilisateur suite demande confirmation: {answer}")
    if output_mode == "dash":
        user_msg = html.Div(f"ğŸ‘¤ {answer}", className="user-message")
    else:
        user_msg = {"role": "user", "text": user_input.strip()}

    chat_history.append(user_msg)


    full_user_input = session["intent_candidate"]["full_user_input"]
    print(f'âš ï¸handle_confirmation_response/full_user_input: {full_user_input}')



    # Intention confirmÃ©e, -> changement Ã©tat de intent_confirmation_pending
    if answer in ["oui", "yes", "ok", "c'est bien Ã§a"]:
        session["intent_confirmation_pending"] = False
        intent = session["intent_candidate"]["intent"]
        nom = session["intent_candidate"]["name"]

        # DÃ©finition des flags
        ppa_requested = intent == "generate_ppa"
        constantes_requested = intent == "get_constants"
        recommandations_requested = intent == "generate_recommendations"
        print(f"âœ… Intention confirmÃ©e par lâ€™utilisateur : {intent}")

        print(f"ğŸ¯ Intentions dÃ©tectÃ©es : "
              f"recommandations: {recommandations_requested},"
              f"constantes={constantes_requested}, "
              f"ppa={ppa_requested}, "
              f"nom patient={nom}")
        print(f'âœ…dÃ©tection intention rÃ©ussie')

        # On dÃ©clenche l'un des pipelines suivants selon l'intention dÃ©tectÃ©e
        # --- RÃ©initialisation si changement de patient ---
        if nom and (ppa_requested or constantes_requested or recommandations_requested):
            if nom and nom != current_patient:
                print(f"ğŸ”´ Changement de patient dÃ©tectÃ© : {current_patient} â¡ï¸ {nom}")

                # âš ï¸ Reset du delta SANS perdre le message utilisateur dÃ©jÃ  capturÃ©
                chat_history = [user_msg]
                figs_list = []
                table_html = ""
                anomaly_block = ""
                current_patient = nom

                # Remet Ã  zÃ©ro le mapping dâ€™anonymisation
                session_manager_instance.reset_anonymization_mapping(user_id)
                session_manager_instance.set_current_patient(session_id, nom)

            else:
                print(f"âœ… Patient conservÃ© : {current_patient}")

        # --- Traitement des constantes ---
        if constantes_requested:
            try:
                print("ğŸ“Š Appel Ã  process_patient_request_with_constants()")
                bot_response, figs_list, table_html, anomaly_block = process_patient_request_with_constants(nom)

                if output_mode == "dash":
                    # âœ… Mode UI Dash: sÃ©rialisation pour dcc.Store
                    serialized_figs = serialize_figs(figs_list)
                    figures_out = figs_list  # pour construire dcc.Graph cÃ´tÃ© callback
                else:
                    # âœ… Mode API: JSON Plotly directement exploitable cÃ´tÃ© OBY
                    figures_out = [fig.to_plotly_json() for fig in figs_list]
                    serialized_figs = None

            except Exception as e:
                print(f"âŒ Erreur dans process_patient_request_with_constants : {e}")
                bot_response = "Une erreur est survenue pendant le traitement des constantes."
                figs_list, table_html, anomaly_block = [], "", ""


                # --- Traitement demande PPA ---
        elif ppa_requested:
            print("ğŸ“„ Appel Ã  process_ppa_request() pour le PPA")
            try:
                bot_response, dict_mapping = process_ppa_request(full_user_input, system_prompt)

                # Enregistrer le mapping renvoyÃ© par la fonction dans la session
                # Le rÃ©cupÃ©rer proprement via session_manager.get_anonymization_mapping()
                session_manager_instance.set_anonymization_mapping(session_id, dict_mapping)

                # Quand le LLM a donnÃ© une rÃ©ponse (bot_response), ajout de la rÃ©ponse dans la session
                session_manager_instance.append_llm_response(session_id, bot_response)

                # âœ… Ajout Ã©change complet (question + rÃ©ponse)
                session = session_manager_instance.get_session(session_id)
                session_obj = session.get("session_obj")
                if session_obj:
                    session_obj.add_message(user_input, bot_response)

                figs_list, table_html, anomaly_block = [], "", ""

            except Exception as e:
                print(f"âŒ Erreur dans process_ppa_request : {e}")
                bot_response = "Une erreur est survenue pendant la gÃ©nÃ©ration du PPA."
                figs_list, table_html, anomaly_block = [], "", ""


        # --- Traitement demande plan de soins ---
        elif recommandations_requested:
            print("ğŸ“„ Appel Ã  generate_structured_medical_plan() pour plan de soins")
            try:
                bot_response, dict_mapping = generate_structured_medical_plan(full_user_input,
                                                                              system_prompt_medical_plan)

                # Enregistrer le mapping renvoyÃ© par la fonction dans la session
                # Le rÃ©cupÃ©rer proprement via session_manager.get_anonymization_mapping()
                session_manager_instance.set_anonymization_mapping(session_id, dict_mapping)

                # Quand le LLM a donnÃ© une rÃ©ponse (bot_response), ajout de la rÃ©ponse dans la session
                print("ğŸ”´before -> session_manager_instance.append_llm_response(session_id, bot_response")
                session_manager_instance.append_llm_response(session_id, bot_response)
                print("ğŸ”´after -> session_manager_instance.append_llm_response(session_id, bot_response")

                # âœ… Ajouter lâ€™Ã©change complet (question + rÃ©ponse)
                print("ğŸ”´before -> session_manager_instance.get_session(session_id)")
                session = session_manager_instance.get_session(session_id)
                print("ğŸ”´after -> session_manager_instance.get_session(session_id)")
                session_obj = session.get("session_obj")
                if session_obj:
                    print("ğŸ”´before -> session_obj.add_message(user_input, bot_response)")
                    session_obj.add_message(user_input, bot_response)
                    print("ğŸ”´after -> session_obj.add_message(user_input, bot_response)")

                figs_list, table_html, anomaly_block = [], "", ""

            except Exception as e:
                print(f"âŒ Erreur dans generate_structured_medical_plan : {e}")
                bot_response = "Une erreur est survenue pendant l'extraction des recommandations de soins."
                figs_list, table_html, anomaly_block = [], "", ""



    else:
        # Rejet de lâ€™intention
        session["intent_confirmation_pending"] = False
        session["intent_candidate"] = {"intent": None, "name": None, "full_user_input": ""}

        bot_response = (
            "Compris. Voici quelques exemples de requÃªtes que vous pouvez utiliser :\n"
            "- *PrÃ©pare-moi le plan dâ€™aide pour Madame Dupont*\n"
            "- *Montre-moi les constantes du patient Martin sur le dernier mois*\n"
            "- *Quelles sont les recommandations en cas dâ€™AVC ?*"
        )

    if bot_response:
        if output_mode == "dash":
            bot_msg = html.Div(
                dcc.Markdown(str(bot_response), dangerously_allow_html=False),
                className="bot-response"
            )
            chat_history.append(bot_msg)
        else:
            chat_history.append({"role": "assistant", "markdown": str(bot_response)})

    chat_history_display = None


    return (chat_history, figures_out, table_html,
            anomaly_block, current_patient,
            serialized_figs, chat_history_display)
