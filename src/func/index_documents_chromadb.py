"""
    Outils d‚Äôindexation ChromaDB pour OBY-IA.

    Ce module expose des utilitaires pour (r√©)indexer des collections ChromaDB
    √† partir de r√©pertoires de JSON structur√©s :
    - `base_docx` : documents d√©riv√©s de fiches DOCX,
    - `base_web`  : documents d√©riv√©s du scraping de sites de confiance.

    Fournit notamment une fonction de reconstruction qui
    supprime la collection cibl√©e puis la reconstruit √† partir des fichiers
    pr√©sents sur disque, garantissant l‚Äôabsence de documents ¬´ fant√¥mes ¬ª
    lorsqu‚Äôil y a des suppressions ou des changements de configuration.

    Fonctions attendues dans ce module (ou import√©es) :
    - `index_documents(source_dir, source_type, client)`: effectue l‚Äôindexation
      √† partir d‚Äôun r√©pertoire JSON (cr√©e la collection si n√©cessaire).
    - `collection_name_for(source_type)`: mappe 'docx'/'web' vers le nom
      de collection ChromaDB (p. ex. 'base_docx' / 'base_web').
    - `rebuild_collection_from_disk(client, source_type, source_dir)`: supprime
      la collection puis r√©indexe depuis le disque (cf. docstring ci-dessous).

"""


from uuid import uuid4
from datetime import datetime
import os, json
from chromadb.api import ClientAPI
from chromadb.utils import embedding_functions
from src.utils.chroma_client import get_chroma_client

from config.config import EMBEDDING_MODEL_NAME


def _collection_name_for(source_type: str) -> str:
    """Retourne le nom de collection ChromaDB pour un `source_type` donn√©.

        Args:
            source_type: 'docx' ou 'web'.

        Returns:
            Nom de collection (p. ex. 'base_docx' ou 'base_web').

        Raises:
            ValueError: si `source_type` n‚Äôest pas 'docx' ni 'web'.
    """

    if source_type not in {"docx", "web"}:
        raise ValueError(f"source_type invalide: {source_type!r} (attendus: 'docx' ou 'web')")
    return "base_docx" if source_type == "docx" else "base_web"



def rebuild_collection_from_disk(client: ClientAPI, source_type: str, source_dir: str) -> None:
    """
    Reconstruit enti√®rement la collection ChromaDB d‚Äôun type donn√©.

    Objectif: garantir la coh√©rence parfaite entre l‚Äô√©tat
    disque (r√©pertoire JSON) et l‚Äôindex ChromaDB (par ex. apr√®s suppressions
    de fichiers, changements de configuration des sites, migration d‚Äôembedding,
    etc.).

    1) supprime la collection cibl√©e (si elle existe),
    2) (re)cr√©e et r√©indexe la collection en appelant `index_documents`
       √† partir des JSON pr√©sents dans `source_dir`.

    Args:
        client: instance ChromaDB (ClientAPI) d√©j√† initialis√©e.
        source_type: 'docx' ou 'web' (d√©termine la collection √† reconstruire).
        source_dir: chemin du r√©pertoire contenant les JSON √† indexer.

    Raises:
        ValueError: si `source_type` n‚Äôest pas 'docx' ni 'web'.
        Exception: si la suppression ou la r√©indexation √©choue (erreurs du client
            ChromaDB ou d‚ÄôE/S remont√©es telles quelles).

    Returns:
        None

    """

    name = _collection_name_for(source_type)
    try:
        client.delete_collection(name=name)
        print(f"üî¥ Collection supprim√©e : {name}")
    except Exception as e:
        print(f"üî¥ Impossible de supprimer (peut-√™tre absente) {name} : {e}")
    # R√©indexation compl√®te depuis le r√©pertoire (cr√©e la collection si besoin)
    index_documents(source_dir=source_dir, source_type=source_type, client=client)
    print(f"‚úÖ Collection reconstruite : {name}")


def index_documents(source_dir: str, source_type: str, client: ClientAPI):
    """
    Indexe les documents JSON contenus dans un r√©pertoire dans une collection ChromaDB.

    Chaque document est d√©coup√© en sections (ou chunk unique dans le cas d'un fichier DOCX complet),
    puis ins√©r√© dans une base vectorielle avec ses m√©tadonn√©es.

    Args:
        source_dir (str): Chemin du dossier contenant les fichiers JSON √† indexer.
        source_type (str): Type de document √† indexer, soit 'docx' soit 'web'.
        client (Client): Instance du client ChromaDB utilis√©e pour la persistance des donn√©es.

    Entr√©es :
        - source_dir (str) : Dossier contenant les fichiers JSON.
        - source_type (str) : 'docx' ou 'web' (d√©termine la collection cible).

    Sorties :
        - Indexation des chunks dans une collection nomm√©e selon la source.


    Raises:
        ValueError: Si le type de source est invalide (autre que 'docx' ou 'web').
    """

    print("üü° Lancement fonction -> index_documents()... ")
    if client is None:
        client = get_chroma_client()

    if source_type not in ("docx", "web"):
        raise ValueError("source_type doit √™tre 'docx' ou 'web'.")

    collection_name = "base_docx" if source_type == "docx" else "base_web"

    # üîπ Initialisation collection
    print(f'üü°Initialisation de la collection {collection_name}...')
    embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name=EMBEDDING_MODEL_NAME
    )

    collection = client.get_or_create_collection(name=collection_name, embedding_function=embedding_fn)

    print(f"üü°Indexation des documents depuis : {source_dir} (type: {source_type})")

    total_files, indexed_chunks = 0, 0

    for file in os.listdir(source_dir):
        if not file.endswith(".json"):
            continue
        print(f"üü° Traitement du fichier JSON : {file}")

        file_path = os.path.join(source_dir, file)
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
        except Exception as e:
            print(f"‚ùå Erreur de lecture {file}: {e}")
            continue

        fiches = data if isinstance(data, list) else [data]

        for fiche in fiches:
            print(
                f"‚û°Ô∏è Titre fiche : {fiche.get('titre', 'Sans titre')} - Source : {fiche.get('source_url', 'inconnue')}")
            titre = fiche.get("titre", "Titre inconnu")
            type_document = fiche.get("type_document", "document")
            source = fiche.get("source_doc" if source_type == "docx" else "source_url", "Source inconnue")

            if source_type == "docx":
                # ‚úÖ 1 seul chunk : texte complet
                chunk_text = fiche.get("texte_complet", "").strip()
                if not chunk_text:
                    print(f"‚ö†Ô∏è Texte vide pour le fichier {file}, source_type : {source_type}")
                    continue

                chunk_id = f"{file}_{uuid4().hex[:8]}"
                try:
                    collection.add(
                        documents=[chunk_text],
                        ids=[chunk_id],
                        metadatas=[{
                            "titre": titre,
                            "type_document": type_document,
                            "source": source,
                            "section_index": 0,
                            "source_type": source_type,
                            "date_indexation": datetime.now().strftime("%Y-%m-%d"),
                        }]
                    )
                    indexed_chunks += 1
                except Exception as e:
                    print(f"‚ùå Erreur d‚Äôajout depuis {file} : {e}")


            elif source_type == "web":
                sections = fiche.get("sections", [])
                if not sections:
                    print(f"‚ö†Ô∏è Aucune section trouv√©e dans le fichier {file}, source_type : {source_type}")
                    continue

                for i, section in enumerate(sections):
                    chunk_text = section.get("texte", "").strip()
                    if not chunk_text:
                        print(f"‚ö†Ô∏è Chunk vide dans section {i} du fichier {file}")
                        continue

                    chunk_id = f"{file}_{uuid4().hex[:8]}"
                    try:
                        collection.add(
                            documents=[chunk_text],
                            ids=[chunk_id],
                            metadatas=[{
                                "titre": titre,
                                "type_document": type_document,
                                "source": source,
                                "section_index": i,
                                "source_type": source_type,
                                "date_indexation": datetime.now().strftime("%Y-%m-%d"),
                            }]
                        )
                        indexed_chunks += 1
                    except Exception as e:
                        print(f"‚ùå Erreur d'ajout d'une section depuis {file}, section {i} : {e}")


        total_files += 1

    print(f"‚úÖ {indexed_chunks} sections index√©es √† partir de {total_files} fichiers.")

