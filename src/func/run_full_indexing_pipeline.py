"""
Module `run_full_indexing_pipeline.py` ‚Äì Pipeline principal d‚Äôindexation documentaire pour OBY-IA.

Ce module ex√©cute l‚Äôensemble du processus de pr√©paration de la base documentaire utilis√©e
par les agents RAG de OBY-IA, en assurant une indexation vectorielle actualis√©e dans ChromaDB.

Fonctionnalit√©s couvertes :
1. **D√©tection de modifications** :
   - Identification des fichiers DOCX ou pages web r√©cemment modifi√©s via calcul de hashs.
   - D√©tection des changements dans la d√©finition des sites de confiance (`trusted_sites.py`).

2. **Conversion en JSON structur√©** :
   - Transformation des fichiers DOCX en fichiers JSON exploitables.
   - Scraping et structuration des nouvelles pages web selon les r√®gles d√©finies.

3. **Indexation vectorielle dans ChromaDB** :
   - Indexation incr√©mentale ou compl√®te des donn√©es selon les changements d√©tect√©s.
   - S√©paration des sources DOCX et web (`source_type`).

4. **Journalisation des indexations** :
   - Mise √† jour du fichier de suivi (`indexed_files.json`) pour √©viter les r√©indexations inutiles.

5. **Signalement de disponibilit√©** :
   - √âcriture d‚Äôun fichier `index_ready.flag` permettant aux autres modules de savoir si l‚Äôindex est pr√™t.

Ce pipeline peut √™tre lanc√© :
- automatiquement (via un scheduler ou watchdog),
- ou manuellement (en ex√©cutant ce fichier en tant que script).

Il constitue un composant critique du syst√®me OBY-IA pour garantir la fra√Æcheur et la coh√©rence
des bases documentaires utilis√©es dans les interactions LLM + RAG.
"""




from src.utils.convert_fiches_docx_to_json import convert_and_save_fiches
from config.config import INPUT_DOCX, JSON_HEALTH_DOC_BASE, WEB_SITES_JSON_HEALTH_DOC_BASE
from pathlib import Path
from src.func.indexed_health_related_files import (
    detect_changes_and_get_modified_files,
    update_index_journal,
)
from src.func.scrape_trusted_sites import scrape_all_trusted_sites
from src.func.index_documents_chromadb import index_documents
from src.utils.chroma_client import get_chroma_client
from src.utils.vector_db_utils import mark_index_ready_flag, clear_index_ready_flag


def run_full_indexing_pipeline():
    """
    Ex√©cute le pipeline complet d‚Äôindexation des documents m√©dicaux.

    Ce pipeline effectue les √©tapes suivantes :
    1. D√©tection des fichiers modifi√©s (DOCX, JSON web, fichier des sites de confiance).
    2. Conversion des fichiers DOCX en JSON.
    3. Scraping et structuration des pages web si n√©cessaire.
    4. Indexation vectorielle des fichiers convertis (DOCX et web) dans ChromaDB.
    5. Mise √† jour du journal des fichiers index√©s.

    Ce processus permet d'assurer que la base documentaire est √† jour pour les requ√™tes RAG.
    """

    clear_index_ready_flag()

    print("üöÄ 1.Lancement du pipeline d'indexation...")
    print(f"üìÇ 2. Dossier d'entr√©e DOCX : {INPUT_DOCX}")

    # √âtape 1 ‚Äì D√©tection des changements
    changes_dict = detect_changes_and_get_modified_files()
    docx_files_to_index = changes_dict.get("docx_files_to_index", [])
    web_files_to_index = changes_dict.get("web_files_to_index", [])
    trusted_sites_changed = changes_dict.get("trusted_sites_py_changed", False)
    current_docx_hashes = changes_dict.get("current_docx_hashes", {})
    current_web_hashes = changes_dict.get("current_web_hashes", {})
    current_py_hash = changes_dict.get("current_py_hash", None)

    print(f"üîç DOCX √† indexer : {len(docx_files_to_index)} fichiers")
    print(f"üîç WEB √† indexer : {len(web_files_to_index)} fichiers")
    print(f"üîç Files trusted_sites.py modifi√© ? {trusted_sites_changed}")

    # DOCX : indexation initiale ou incr√©mentale
    if not current_docx_hashes:
        print("üÜï Premi√®re indexation des fichiers DOCX...")
        all_docx_files = list(Path(INPUT_DOCX).glob("*.docx"))


        print(f"üìÇ Dossier d'entr√©e DOCX : {INPUT_DOCX}")
        print(f"üìÑ Fichiers trouv√©s : {all_docx_files}")

        for docx_file in all_docx_files:
            convert_and_save_fiches(str(docx_file), JSON_HEALTH_DOC_BASE)
    else:
        if docx_files_to_index:
            print("üõ†Ô∏è 3. Conversion des fiches DOCX modifi√©es...")
            for docx_file in docx_files_to_index:
                print(f'4. docx_file: {docx_file}')
                convert_and_save_fiches(str(docx_file), JSON_HEALTH_DOC_BASE)

    # WEB : indexation initiale ou conditionnelle
    if not current_web_hashes or trusted_sites_changed:
        print("üåê Indexation compl√®te des sources web...")
        scrape_all_trusted_sites()
    elif web_files_to_index:
        print("üåê Indexation partielle : nouvelles pages web d√©tect√©es...")
        scrape_all_trusted_sites()

    # √âtape 4 ‚Äì Construction index vectoriel si n√©cessaire
    if docx_files_to_index or web_files_to_index or trusted_sites_changed:
        print("üìö Construction d'un nouvel index vectoriel...")
        client = get_chroma_client()
        index_documents(JSON_HEALTH_DOC_BASE, source_type="docx", client=client)
        index_documents(WEB_SITES_JSON_HEALTH_DOC_BASE, source_type="web", client=client)
    else:
        print("‚úÖ Aucun changement d√©tect√©, indexation non n√©cessaire.")

    # √âtape 5 ‚Äì Mise √† jour du journal des fichiers
    update_index_journal(
        new_docx_hashes=current_docx_hashes,
        new_web_hashes=current_web_hashes,
        new_py_hash=current_py_hash,
    )
    print("‚úÖ Pipeline termin√© avec succ√®s !")


mark_index_ready_flag()


# Ex√©cution directe possible
if __name__ == "__main__":
    run_full_indexing_pipeline()
    mark_index_ready_flag()
