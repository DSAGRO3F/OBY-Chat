"""
Module extract_user_intent

Ce module permet de dÃ©tecter lâ€™intention principale dâ€™un utilisateur Ã  partir de sa requÃªte textuelle.
La dÃ©tection repose dâ€™abord sur des correspondances par mots-clÃ©s, puis bascule sur un modÃ¨le de langage
(LLM) si aucune correspondance directe nâ€™est trouvÃ©e.

Modifications apportÃ©es :
- Ajout dâ€™une hiÃ©rarchie de prioritÃ© dans la dÃ©tection par mots-clÃ©s pour rÃ©soudre les ambiguÃ¯tÃ©s.
- Ajout de docstrings conformes Ã  la PEP 257.
- Refactorisation avec Ã©tapes explicites et commentaires clairs.
"""

from typing import Dict, Literal
from langchain_core.language_models import BaseLanguageModel
from src.llm_user_session.model import llm_model


IntentType = Literal["generate_ppa", "get_constants", "generate_recommendations", "unknown"]

# ğŸ”‘ Mots-clÃ©s associÃ©s Ã  chaque intention
intent_keywords = {
    "generate_ppa": [
        "plan d'accompagnement", "ppa", "gÃ©nÃ©rer un ppa", "objectifs et actions", "proposer un plan",
        "Ã©laborer un ppa", "plan personnalisÃ©", "prÃ©parer le plan", "faire un plan pour le patient",
        "crÃ©er un plan", "rÃ©diger le plan", "plan Ã  mettre en place", "plan Ã  faire",
        "prÃ©vois un accompagnement", "plan du patient", "mettre en place le suivi",
        "organiser le plan de soins", "dÃ©finir un plan", "construire le plan"
    ],

    "get_constants": [
        "constantes", "tension", "poids", "tempÃ©rature", "frÃ©quence cardiaque", "graphique",
        "affiche les constantes", "Ã©volution", "valeurs biologiques", "donnÃ©es de santÃ©",
        "historique mÃ©dical", "voir les courbes", "montre moi les constantes", "valeurs mesurÃ©es",
        "graphique du patient", "Ã©tat de santÃ©", "rÃ©sumÃ© mÃ©dical", "suivi des constantes",
        "affiche les mesures", "statistiques de santÃ©", "courbe de poids", "tendance mÃ©dicale"
    ],

    "generate_recommendations": [
        "conduite Ã  tenir", "prise en charge", "recommandations", "quoi faire", "traitement",
        "agir", "soins Ã  apporter", "prÃ©vention", "risque", "urgence", "aide pour un cas",
        "prise de dÃ©cision", "avis mÃ©dical", "diagnostic", "que faire", "quelle dÃ©marche suivre",
        "comment rÃ©agir", "que dois-je faire", "orientation mÃ©dicale", "dÃ©cision mÃ©dicale",
        "protocole Ã  suivre", "rÃ©ponse adaptÃ©e", "conseils de soins", "suggestion dâ€™action",
        "mesures Ã  prendre", "plan dâ€™action Ã  suivre"
    ]
}

# âš–ï¸ PrioritÃ© des intentions (plus haut = plus prioritaire)
intent_priority = {
    "get_constants": 1,
    "generate_ppa": 2,
    "generate_recommendations": 3
}


# Fonction de normalisation du texte
import unicodedata
import re

def normalize_text(text: str) -> str:
    """
    Nettoie et standardise une chaÃ®ne de texte en franÃ§ais pour faciliter la dÃ©tection dâ€™intention.

    Ã‰tapes :
    - Passage en minuscules
    - Remplacement des apostrophes typographiques
    - Suppression des accents
    - Suppression des caractÃ¨res non alphanumÃ©riques utiles
    - Nettoyage des espaces multiples

    Args:
        text (str): Texte Ã  normaliser

    Returns:
        str: Texte nettoyÃ© et standardisÃ©
    """
    if not text:
        return ""

    # Minuscule
    text = text.lower()

    # Uniformisation des apostrophes et caractÃ¨res typographiques
    text = text.replace("â€™", "'").replace("â€˜", "'").replace("`", "'")

    # Suppression des accents (ex : Ã© â†’ e)
    text = ''.join(
        c for c in unicodedata.normalize('NFD', text)
        if unicodedata.category(c) != 'Mn'
    )

    # Suppression des caractÃ¨res spÃ©ciaux inutiles sauf apostrophes et chiffres
    text = re.sub(r"[^a-z0-9' ]", " ", text)

    # Remplacement des espaces multiples par un seul
    text = re.sub(r"\s+", " ", text)

    # Trim final
    return text.strip()



def detect_user_intent(user_input: str) -> Dict[str, str]:
    """
    DÃ©tecte lâ€™intention de lâ€™utilisateur Ã  partir de sa requÃªte textuelle.

    La fonction effectue :
    1. Une dÃ©tection par mots-clÃ©s avec hiÃ©rarchie de prioritÃ© si plusieurs intentions sont dÃ©tectÃ©es.
    2. Un fallback par modÃ¨le de langage (LLM) si aucune correspondance nâ€™est trouvÃ©e.

    Args:
        user_input (str): RequÃªte utilisateur.

    Returns:
        dict: Dictionnaire contenant une seule clÃ© "intent" avec lâ€™une des valeurs suivantes :
              "generate_ppa", "get_constants", "generate_recommendations", ou "unknown".
    """
    if not user_input:
        return {"intent": "unknown"}

    user_input_norm = normalize_text(user_input)

    # ğŸ” Ã‰tape 1 : Recherche des intentions par mots-clÃ©s
    matched_intents = []
    for intent, keywords in intent_keywords.items():
        for keyword in keywords:
            if keyword in user_input_norm:
                matched_intents.append(intent)
                break  # Un seul mot-clÃ© suffit Ã  activer une intention

    # âš–ï¸ Ã‰tape 2 : SÃ©lection de lâ€™intention dominante par prioritÃ©
    if matched_intents:
        selected_intent = max(matched_intents, key=lambda i: intent_priority[i])
        print(f"ğŸ” Intention dÃ©tectÃ©e par mot-clÃ© : {selected_intent}")
        return {"intent": selected_intent}

    # ğŸ§  Ã‰tape 3 : Fallback â€“ classification via LLM
    print("ğŸ§  Aucune correspondance simple trouvÃ©e, appel au LLM pour classification...")
    response = llm_intent_classification(user_input)

    # âœ… VÃ©rification du rÃ©sultat du LLM
    if response in intent_priority:
        return {"intent": response}

    print("âš ï¸ Intention non reconnue aprÃ¨s passage au LLM.")
    return {"intent": "unknown"}



def llm_intent_classification(user_input: str, llm: BaseLanguageModel = None) -> IntentType:
    """
    Utilise un modÃ¨le de langage (LLM) pour infÃ©rer lâ€™intention utilisateur si aucun mot-clÃ© ne correspond.

    Args:
        user_input (str): RequÃªte de lâ€™utilisateur.
        llm (BaseLanguageModel, optional): ModÃ¨le LLM. Si None, le modÃ¨le par dÃ©faut est utilisÃ©.

    Returns:
        IntentType: Intention dÃ©tectÃ©e ("generate_ppa", "get_constants", "generate_recommendations", ou "unknown").
    """
    if llm is None:
        llm = llm_model

    # ğŸ”§ Prompt systÃ¨me renforcÃ© pour guider le modÃ¨le
    system_prompt = """
Tu es un assistant expert en classification dâ€™intentions pour une application appelÃ©e OBY-IA.

Lâ€™utilisateur peut Ã©crire en langage naturel comme sâ€™il sâ€™adressait Ã  ChatGPT. Ta tÃ¢che est de lire sa requÃªte et de dÃ©terminer lâ€™intention principale Ã  dÃ©clencher.

Voici les intentions disponibles :

- generate_ppa : si lâ€™utilisateur veut gÃ©nÃ©rer un Plan PersonnalisÃ© dâ€™Accompagnement (PPA) Ã  partir dâ€™un document patient.
- get_constants : si lâ€™utilisateur veut afficher les constantes mÃ©dicales (ex : tension, tempÃ©rature, poids, frÃ©quence cardiaque, graphiquesâ€¦).
- generate_recommendations : si lâ€™utilisateur veut obtenir des recommandations mÃ©dicales, une conduite Ã  tenir, un traitement, ou savoir comment agir.
- unknown : si la requÃªte est trop floue ou ne correspond Ã  aucun de ces cas.

Tu dois rÃ©pondre **uniquement** avec le mot-clÃ© correspondant, sans ponctuation, sans phrase, sans commentaire.

Exemples valides : generate_ppa / get_constants / generate_recommendations / unknown

Phrase utilisateur :
{user_input}

Intention :
""".strip()

    prompt = system_prompt.format(user_input=user_input.strip())

    try:
        response = llm.invoke(prompt).content.strip().lower()
        print(f"ğŸ¤– Intention dÃ©tectÃ©e via LLM : {response}")
        return response if response in intent_priority else "unknown"
    except Exception as e:
        print(f"âš ï¸ Erreur LLM dans la dÃ©tection dâ€™intention : {e}")
        return "unknown"

