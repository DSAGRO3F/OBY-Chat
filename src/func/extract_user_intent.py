"""
Module extract_user_intent

Ce module permet de d√©tecter l‚Äôintention principale d‚Äôun utilisateur √† partir de sa requ√™te textuelle.
La d√©tection repose d‚Äôabord sur des correspondances par mots-cl√©s, puis bascule sur un mod√®le de langage
(LLM) si aucune correspondance directe n‚Äôest trouv√©e.

Modifications apport√©es :
- Ajout d‚Äôune hi√©rarchie de priorit√© dans la d√©tection par mots-cl√©s pour r√©soudre les ambigu√Øt√©s.
- Ajout de docstrings conformes √† la PEP 257.
- Refactorisation avec √©tapes explicites et commentaires clairs.
"""

from typing import Dict, Literal
from langchain_core.language_models import BaseLanguageModel
from src.llm_user_session.model import llm_model


IntentType = Literal["generate_ppa", "get_constants", "generate_recommendations", "unknown"]

# üîë Mots-cl√©s associ√©s √† chaque intention
intent_keywords = {
    "generate_ppa": [
        "plan d'accompagnement", "ppa", "g√©n√©rer un ppa", "objectifs et actions", "proposer un plan",
        "√©laborer un ppa", "plan personnalis√©"
    ],
    "get_constants": [
        "constantes", "tension", "poids", "temp√©rature", "fr√©quence cardiaque", "graphique",
        "affiche les constantes", "√©volution", "valeurs biologiques"
    ],
    "generate_recommendations": [
        "conduite √† tenir", "prise en charge", "recommandations", "quoi faire", "traitement",
        "agir", "soins √† apporter", "pr√©vention", "risque", "urgence", "aide pour un cas",
        "prise de d√©cision", "avis m√©dical", "diagnostic"
    ],
}

# ‚öñÔ∏è Priorit√© des intentions (plus haut = plus prioritaire)
intent_priority = {
    "get_constants": 1,
    "generate_ppa": 2,
    "generate_recommendations": 3
}


def detect_user_intent(user_input: str) -> Dict[str, str]:
    """
    D√©tecte l‚Äôintention de l‚Äôutilisateur √† partir de sa requ√™te textuelle.

    La fonction effectue :
    1. Une d√©tection par mots-cl√©s avec hi√©rarchie de priorit√© si plusieurs intentions sont d√©tect√©es.
    2. Un fallback par mod√®le de langage (LLM) si aucune correspondance n‚Äôest trouv√©e.

    Args:
        user_input (str): Requ√™te utilisateur.

    Returns:
        dict: Dictionnaire contenant une seule cl√© "intent" avec l‚Äôune des valeurs suivantes :
              "generate_ppa", "get_constants", "generate_recommendations", ou "unknown".
    """
    if not user_input:
        return {"intent": "unknown"}

    user_input_lower = user_input.lower().strip()

    # üîç √âtape 1 : Recherche des intentions par mots-cl√©s
    matched_intents = []
    for intent, keywords in intent_keywords.items():
        for keyword in keywords:
            if keyword in user_input_lower:
                matched_intents.append(intent)
                break  # Un seul mot-cl√© suffit √† activer une intention

    # ‚öñÔ∏è √âtape 2 : S√©lection de l‚Äôintention dominante par priorit√©
    if matched_intents:
        selected_intent = max(matched_intents, key=lambda i: intent_priority[i])
        print(f"üîç Intention d√©tect√©e par mot-cl√© : {selected_intent}")
        return {"intent": selected_intent}

    # üß† √âtape 3 : Fallback ‚Äì classification via LLM
    print("üß† Aucune correspondance simple trouv√©e, appel au LLM pour classification...")
    response = llm_intent_classification(user_input)

    # ‚úÖ V√©rification du r√©sultat du LLM
    if response in intent_priority:
        return {"intent": response}

    print("‚ö†Ô∏è Intention non reconnue apr√®s passage au LLM.")
    return {"intent": "unknown"}


def llm_intent_classification(user_input: str, llm: BaseLanguageModel = None) -> IntentType:
    """
    Utilise un mod√®le de langage (LLM) pour inf√©rer l‚Äôintention utilisateur si aucun mot-cl√© ne correspond.

    Args:
        user_input (str): Texte de l‚Äôutilisateur.
        llm (BaseLanguageModel, optional): Mod√®le √† utiliser. Si None, un mod√®le local est charg√©.

    Returns:
        IntentType: Intention d√©tect√©e, ou "unknown".
    """
    if llm is None:
        llm = llm_model()

    # üßæ Prompt syst√®me pour le classificateur d‚Äôintentions
    system_prompt = """
Tu es un classificateur d'intentions. Ton travail est de lire une phrase d'utilisateur et de d√©terminer l‚Äôintention parmi les choix suivants :
- generate_ppa
- get_constants
- generate_recommendations

Si aucune intention ne correspond, retourne "unknown".

R√©ponds uniquement avec le mot-cl√© de l‚Äôintention.
"""

    prompt = f"{system_prompt}\n\nPhrase utilisateur : {user_input}\n\nIntention :"

    try:
        response = llm.invoke(prompt).content.strip().lower()
        print(f"ü§ñ Intention d√©tect√©e via LLM : {response}")
        return response if response in intent_priority else "unknown"
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur LLM dans la d√©tection d‚Äôintention : {e}")
        return "unknown"






# ==================================================
# Code insuffisant pour d√©tection intention correcte
# ==================================================
# IntentType = Literal["generate_ppa", "get_constants", "generate_recommendations", "unknown"]
#
# # ‚úÖ Dictionnaire de mots-cl√©s associ√©s √† chaque intention
# intent_keywords = {
#     "generate_ppa": [
#         "plan d'accompagnement", "ppa", "g√©n√©rer un ppa", "objectifs et actions", "proposer un plan",
#         "√©laborer un ppa", "plan personnalis√©"
#     ],
#     "get_constants": [
#         "constantes", "tension", "poids", "temp√©rature", "fr√©quence cardiaque", "graphique",
#         "affiche les constantes", "√©volution", "valeurs biologiques"
#     ],
#     "generate_recommendations": [
#         "conduite √† tenir", "prise en charge", "recommandations", "quoi faire", "traitement",
#         "agir", "soins √† apporter", "pr√©vention", "risque", "urgence", "aide pour un cas",
#         "prise de d√©cision", "avis m√©dical", "diagnostic"
#     ],
# }
#
#
# def detect_user_intent(user_input: str) -> Dict[str, str]:
#     """
#     D√©tecte l‚Äôintention de l‚Äôutilisateur √† partir de sa requ√™te.
#
#     Effectue d'abord une recherche par mots-cl√©s, puis utilise un LLM si aucune correspondance n‚Äôest trouv√©e.
#
#     Args:
#         user_input (str): Requ√™te de l‚Äôutilisateur sous forme de texte.
#
#     Returns:
#         dict: Dictionnaire contenant une cl√© "intent" avec la valeur correspondante.
#               Exemple : {"intent": "get_constants"}
#     """
#     if not user_input:
#         return {"intent": "unknown"}
#
#     user_input_lower = user_input.lower()
#
#     # üîç √âtape 1 : Matching par mots-cl√©s simples
#     for intent, keywords in intent_keywords.items():
#         for keyword in keywords:
#             if keyword in user_input_lower:
#                 print(f"üîç Intention d√©tect√©e par mot-cl√© : {intent}")
#                 print(f'‚úîÔ∏ètype for intent output: {type(intent)}')
#                 return {"intent": intent}
#
#     # üîç √âtape 2 : Fallback ‚Äì classification LLM
#     print("üß† Aucune correspondance simple trouv√©e, appel au LLM pour classification...")
#     response = llm_intent_classification(user_input)
#
#     if response is None:
#         print("‚ö†Ô∏è Le LLM n‚Äôa retourn√© aucune intention. Valeur None intercept√©e.")
#         return {"intent": "unknown"}
#
#     if response in ["generate_ppa", "get_constants", "generate_recommendations"]:
#         return {"intent": response}
#
#     print(f'type for intent output: {type(response)}')
#
#     return {"intent": "unknown"}
#
#
# def llm_intent_classification(user_input: str, llm: BaseLanguageModel = None) -> IntentType:
#     """
#     Utilise un LLM pour inf√©rer l'intention quand aucun mot-cl√© ne correspond.
#
#     Args:
#         user_input (str): Message de l'utilisateur.
#         llm (BaseLanguageModel, optional): Mod√®le LangChain. Par d√©faut = mod√®le local.
#
#     Returns:
#         IntentType: Intention inf√©r√©e.
#     """
#     if llm is None:
#         llm = llm_model()
#
#     system_prompt = """
# Tu es un classificateur d'intentions. Ton travail est de lire une phrase d'utilisateur et de d√©terminer l‚Äôintention parmi les choix suivants :
# - generate_ppa
# - get_constants
# - generate_recommendations
#
# Si aucune intention ne correspond, retourne "unknown".
#
# R√©ponds uniquement avec le mot-cl√© de l‚Äôintention.
# """
#     prompt = f"{system_prompt}\n\nPhrase utilisateur : {user_input}\n\nIntention :"
#
#     try:
#         response = llm.invoke(prompt).content.strip().lower()
#         print(f"ü§ñ Intention d√©tect√©e via LLM : {response}")
#         if response in ["generate_ppa", "get_constants", "generate_recommendations"]:
#             return response  # type: ignore
#     except Exception as e:
#         print(f"‚ö†Ô∏è Erreur LLM dans la d√©tection d'intention : {e}")
#
#     return "unknown"
