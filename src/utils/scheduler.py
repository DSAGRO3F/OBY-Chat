# src/utils/scheduler.py
"""
Scheduler de r√©indexation Chroma : surveillance, s√©rialisation et relance s√ªres.

Ce module d√©marre un watchdog des dossiers d‚Äôentr√©e, scrute le flag
`.force_full_index` et lance le pipeline via `_run_pipeline_safely()`,
sous verrou inter-processus. Il effectue une probe d‚Äô√©criture sans
embedder, n‚Äôex√©cute le pipeline que si la base est utilisable, et ne
pose le `index_ready.flag` qu‚Äôen cas de succ√®s, en consommant le flag
de for√ßage ensuite. Il √©vite les acc√®s concurrents √† Chroma pendant
les resets/rebuilds et peut appliquer un backoff sur les relances.

"""
from __future__ import annotations
import os, stat, glob
import sys
import time
import threading
from pathlib import Path
from typing import Optional
from fasteners import InterProcessLock
import getpass

try:
    from chromadb.errors import InternalError
except Exception:
    class InternalError(Exception):
        pass

from config.config import (
                            CHROMA_GLOBAL_DIR,
                            INDEX_READY_FLAG_PATH,
                            FORCE_FULL_INDEX_FLAG,
                            INDEXING_FLAG_FILE,
                            INDEX_IPC_LOCK_PATH,
                           )

from src.func.run_full_indexing_pipeline import run_full_indexing_pipeline

# ‚úÖ Centraliser l'acc√®s client via utils/chroma_client (LRU + reset)
from src.utils.chroma_client import get_chroma_client, reset_chroma_client_cache

# -------------------------------------------------
# Directoires √† surveiller (d√©j√† d√©finis chez toi)
# -------------------------------------------------
from config.config import INPUT_DOCX, WEB_SITES_HEALTH_DOC_BASE

WATCHED_DIRECTORIES = [
    INPUT_DOCX,
    WEB_SITES_HEALTH_DOC_BASE,
]

# -------------------------------------------------
# Flags et verrous
# -------------------------------------------------
INDEX_READY_FLAG = INDEX_READY_FLAG_PATH


# -------------------------------------------------
# Watchdog (avec debounce)
# -------------------------------------------------
try:
    from watchdog.observers import Observer
    from watchdog.events import FileSystemEventHandler
    WATCHDOG_AVAILABLE = True
except Exception:
    WATCHDOG_AVAILABLE = False

# ---

print(f"[scheduler] ready_flag={INDEX_READY_FLAG} force_flag={FORCE_FULL_INDEX_FLAG} lock={INDEX_IPC_LOCK_PATH}")


class _Debouncer:
    def __init__(self, wait_seconds: float = 2.0):
        self.wait = wait_seconds
        self._timer: Optional[threading.Timer] = None
        self._lock = threading.Lock()

    def trigger(self, fn, *args, **kwargs):
        def _fire():
            fn(*args, **kwargs)
        with self._lock:
            if self._timer and self._timer.is_alive():
                self._timer.cancel()
            self._timer = threading.Timer(self.wait, _fire)
            self._timer.daemon = True
            self._timer.start()


class _WatchHandler(FileSystemEventHandler):
    def __init__(self, debouncer: _Debouncer):
        super().__init__()
        self.debouncer = debouncer

    def on_any_event(self, event):
        p = getattr(event, "src_path", "") or ""
        name = os.path.basename(p)
        # ignorer fichiers cach√©s/temp
        if name.startswith(".") or name.endswith("~") or name.endswith(".tmp"):
            return
        self.debouncer.trigger(_run_pipeline_safely, reason=f"watchdog:{event.event_type}:{p}")


# -------------------------------------------------
# Robustesse: probe + wrapper pipeline
# -------------------------------------------------
def _probe_chroma_writable(client) -> None:
    """(DEBUG uniquement) D√©clenche un write avec documents => peut appeler l'embedder."""
    name = f"healthcheck_{os.getpid()}_{int(time.time()*1000)}"
    col = client.get_or_create_collection(name=name)
    try:
        col.add(documents=["ok"], metadatas=[{}], ids=["probe"])
    finally:
        try:
            client.delete_collection(name)
        except Exception:
            pass


def probe_writable_no_embed(c):
    """
    Teste l'√©criture sans d√©clencher d'embed serveur :
    - cr√©e une collection temporaire NOM UNIQUE
    - ajoute 1 vecteur d'embedding "manuel"
    - supprime la collection
    L√®ve en cas d'√©chec (√† g√©rer dans _run_pipeline_safely).
    """
    name = f"healthcheck_tmp_{os.getpid()}_{int(time.time()*1000)}"
    col = c.get_or_create_collection(name=name)
    try:
        col.add(embeddings=[[0.0]*8], metadatas=[{"k": "v"}], ids=["probe"])
        return True
    finally:
        try:
            c.delete_collection(name)
        except Exception:
            pass


def _ensure_writable_dir_now(p: Path):
    p.mkdir(parents=True, exist_ok=True)
    # Permissions minimales (u+rwx)
    try:
        os.chmod(p, stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR)
    except Exception:
        pass
    # Test d'√©criture FS (sans Chroma)
    probe = p / ".fs_write_probe"
    with open(probe, "w", encoding="utf-8") as f:
        f.write("ok")
    probe.unlink(missing_ok=True)

def _cleanup_sqlite_artifacts_now(p: Path):
    for pattern in ("*.wal", "*.shm", "*.lock"):
        for f in p.glob(pattern):
            try:
                f.unlink()
            except Exception:
                pass




INTERPROCESS_LOCK = InterProcessLock(INDEX_IPC_LOCK_PATH)

def _run_pipeline_safely(reason: str = "") -> None:
    """Lance run_full_indexing_pipeline() de fa√ßon s√©rialis√©e, avec verrou IPC, probe no-embed,
    reset client, et pose du ready-flag uniquement en cas de succ√®s."""
    # Cr√©er l'objet de lock IPC (une fois au module de pr√©f√©rence)
    global INTERPROCESS_LOCK
    try:
        INTERPROCESS_LOCK
    except NameError:
        from fasteners import InterProcessLock
        INTERPROCESS_LOCK = InterProcessLock(INDEX_IPC_LOCK_PATH)

    # Tenter de prendre le lock IPC sans bloquer
    acquired = INTERPROCESS_LOCK.acquire(blocking=False)
    if not acquired:
        print(f"‚è≠Ô∏è Rebuild ignor√© (d√©j√† en cours via lock IPC) ‚Äî raison='{reason}'")
        return

    chroma_path = Path(CHROMA_GLOBAL_DIR)
    _cleanup_sqlite_artifacts_now(chroma_path)  # au cas o√π des verrous r√©siduels tra√Ænent
    _ensure_writable_dir_now(chroma_path)

    ok = False
    try:
        # T√©moin d'activit√© (intra/proc et lisible)
        if INDEXING_FLAG_FILE.exists():
            print(f"‚è≠Ô∏è Rebuild ignor√© (flag {INDEXING_FLAG_FILE.name} pr√©sent) ‚Äî raison='{reason}'")
            return
        try:
            INDEXING_FLAG_FILE.touch(exist_ok=False)
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible de cr√©er le flag {INDEXING_FLAG_FILE}: {e}", file=sys.stderr)
            return  # on n'avance pas sans t√©moin fiable

        # Invalider le ready pendant le rebuild
        try:
            INDEX_READY_FLAG.unlink(missing_ok=True)
        except Exception:
            pass

        # Invalider le client avant toute op√©ration
        reset_chroma_client_cache()

        st = os.stat(CHROMA_GLOBAL_DIR)
        print(f"[üüß probe ctx] user={getpass.getuser()} path={CHROMA_GLOBAL_DIR} mode={oct(stat.S_IMODE(st.st_mode))}")
        print(f"[üüß probe ctx] pid={os.getpid()} ipc_lock={INDEX_IPC_LOCK_PATH} "
              f"force={FORCE_FULL_INDEX_FLAG.exists()} indexing={INDEXING_FLAG_FILE.exists()} t={time.time():.0f}")

        # Probe √©criture SANS embed; abort si KO
        try:
            client = get_chroma_client()
            probe_writable_no_embed(client)  # <‚Äî version "nom unique" adopt√©e
        except Exception as e:
            print(f"‚ö†Ô∏è Probe Chroma KO, abandon du pipeline: {e}", file=sys.stderr)
            reset_chroma_client_cache()
            return  # ne pas marquer ready

        # Pipeline (avec retry cibl√© sur readonly/1032)
        try:
            print(f"üü° Lancement pipeline (raison='{reason}')‚Ä¶")
            run_full_indexing_pipeline()
            ok = True
        except InternalError as e:
            msg = str(e).lower()
            print(f"üî¥ InternalError pendant pipeline: {e}", file=sys.stderr)
            if "readonly" in msg or "1032" in msg:
                reset_chroma_client_cache()
                time.sleep(0.5)
                print("‚Üª Retry pipeline apr√®s reset client‚Ä¶")
                run_full_indexing_pipeline()
                ok = True
            else:
                ok = False
                return  # laisser le finally g√©rer sans poser ready
        except Exception as e:
            print(f"üî¥ √âchec pipeline: {e}", file=sys.stderr)
            ok = False
            return

        # Si on arrive ici et ok, poser le ready + consommer le force flag
        if ok:
            try:
                INDEX_READY_FLAG.write_text("ready\n", encoding="utf-8")
                print(f"[DEBUG ‚úÖ] Flag √©crit √† : {INDEX_READY_FLAG}")
            except Exception as e:
                print(f"‚ö†Ô∏è Impossible d‚Äô√©crire le ready flag: {e}", file=sys.stderr)

            try:
                FORCE_FULL_INDEX_FLAG.unlink(missing_ok=True)
                print("[üü® scheduler] force flag consumed")
            except Exception:
                pass

    finally:
        # Nettoyage du flag d‚Äôactivit√© et release du lock
        try:
            INDEXING_FLAG_FILE.unlink(missing_ok=True)
        except Exception:
            pass
        try:
            INTERPROCESS_LOCK.release()
        except Exception:
            pass


def _collections_missing() -> bool:
    """True si base_docx ou base_web manquent (ou si Chroma est indisponible/occup√©e)."""
    # √âvite de sonder Chroma pendant un rebuild en cours
    if INDEXING_FLAG_FILE.exists():
        return True
    try:
        client = get_chroma_client()
        names = [c.name for c in client.list_collections()]
        missing = {"base_docx", "base_web"} - set(names)
        if missing:
            print(f"üü† Collections manquantes : {sorted(missing)}")
            return True
        return False
    except Exception as e:
        msg = str(e).lower()
        if "no such table: tenants" in msg or "readonly" in msg or "1032" in msg:
            print(f"üü† Chroma non initialis√©e/readonly lors du listage: {e}", file=sys.stderr)
        else:
            print(f"‚ö†Ô∏è Impossible de lister les collections: {e}", file=sys.stderr)
        return True


# -------------------------------------------------
# Entr√©e principale
# -------------------------------------------------
def start_scheduler() -> None:
    """
    D√©marre le scheduler de r√©indexation Chroma et la surveillance fichiers.

    Cr√©e le r√©pertoire de persistance au besoin, √©value l‚Äô√©tat initial
    (pr√©sence du ready flag, collections manquantes, demande de rebuild)
    et d√©clenche une r√©indexation si n√©cessaire. Lance un watchdog
    (avec anti-rebond) sur les dossiers d‚Äôentr√©e, puis entre dans une
    boucle qui scrute `.force_full_index` et d√©l√®gue √†
    `_run_pipeline_safely()` sous verrou inter-processus. Cette fonction
    n‚Äôefface pas le flag de for√ßage (consomm√© en cas de succ√®s par le pipeline)
    et arr√™te proprement l‚Äôobserver sur interruption clavier.
    """

    print(f"üü¢ CHROMA_GLOBAL_DIR = {CHROMA_GLOBAL_DIR}")

    # S'assurer que le dossier Chroma existe (permissions d√©j√† g√©r√©es c√¥t√© reset_all_data)
    chroma_dir = Path(CHROMA_GLOBAL_DIR)
    chroma_dir.mkdir(parents=True, exist_ok=True)

    # √âtat initial : ne pas poser le ready.flag si un rebuild est demand√© ou en cours
    if not INDEX_READY_FLAG.exists():
        print("‚ÑπÔ∏è Base pr√©sente mais flag 'ready' absent ‚Äî v√©rification des collections‚Ä¶")
        if FORCE_FULL_INDEX_FLAG.exists() or INDEXING_FLAG_FILE.exists():
            print("‚ÑπÔ∏è Rebuild demand√©/en cours ‚Äî pas de ready.flag pour l‚Äôinstant.")
        elif _collections_missing():
            print("üü† Collections manquantes ‚Üí relance du pipeline d‚Äôindexation.")
            _run_pipeline_safely(reason="startup_missing_ready_or_collections")
        else:
            try:
                INDEX_READY_FLAG.write_text("ready\n", encoding="utf-8")
                print(f"[DEBUG ‚úÖ] Flag √©crit √† : {INDEX_READY_FLAG}")
            except Exception as e:
                print(f"‚ö†Ô∏è Impossible d‚Äô√©crire le ready flag: {e}", file=sys.stderr)
    else:
        print("‚úÖ Index pr√™t (flag pr√©sent).")

    # Watchdog (surveillance temps r√©el des dossiers d'entr√©e)
    observer = None
    if not WATCHDOG_AVAILABLE:
        print("‚ö†Ô∏è Watchdog non disponible ‚Äî aucune surveillance temps r√©el.")
    else:
        debouncer = _Debouncer(wait_seconds=2.0)
        handler = _WatchHandler(debouncer)
        observer = Observer()
        for raw in WATCHED_DIRECTORIES:
            if not raw:
                continue
            d = Path(raw)
            if not d.exists():
                print(f"‚ö†Ô∏è Dossier √† surveiller introuvable : {d}")
                continue
            try:
                observer.schedule(handler, str(d), recursive=True)
                print(f"‚úÖ Surveillance activ√©e sur : {d}")
            except Exception as e:
                print(f"‚ö†Ô∏è Impossible de surveiller {d} : {e}")
        observer.daemon = True
        observer.start()

    # Boucle de poll du flag .force_full_index (consommation g√©r√©e par _run_pipeline_safely)
    try:
        backoff = 1.0
        while True:
            if FORCE_FULL_INDEX_FLAG.exists():
                print("\nüü¢ Flag d√©tect√© √† chaud ‚Üí r√©indexation compl√®te‚Ä¶")
                before = time.time()
                _run_pipeline_safely(reason="force_flag")
                # Si _run_pipeline_safely n'a pas consomm√© le flag (√©chec), on augmente un peu
                if FORCE_FULL_INDEX_FLAG.exists():
                    backoff = min(backoff * 1.5, 30.0)
                else:
                    backoff = 1.0
                elapsed = time.time() - before
                # dormir au moins 'backoff' (mais pas moins que 1s pour ne pas surchauffer)
                time.sleep(max(backoff - elapsed, 1.0))
            else:
                backoff = 1.0
                time.sleep(1.0)

    except KeyboardInterrupt:
        print("\nüõë Arr√™t de la surveillance demand√© (Ctrl+C).")
        if observer:
            observer.stop()
            observer.join()

