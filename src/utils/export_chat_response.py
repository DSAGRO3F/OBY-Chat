"""
Module d'export des rÃ©ponses gÃ©nÃ©rÃ©es par le modÃ¨le LLM pour un patient donnÃ©.

Ce module permet de rÃ©cupÃ©rer toutes les rÃ©ponses associÃ©es Ã  une session,
de les concatÃ©ner proprement, et de les exporter dans un fichier Markdown.
Il peut Ã©galement intÃ©grer des graphiques de constantes si fournis.

UtilisÃ© notamment pour gÃ©nÃ©rer des synthÃ¨ses textuelles enrichies Ã  partir
des sessions de chat dans l'application OBY-IA.
"""

# src/utils/export_chat_response.py

from pathlib import Path
from datetime import datetime
from fpdf import FPDF
from docx import Document
import os
from config.config import MARKDOWN_CHAT_EXPORTS


def export_llm_responses(session_manager_instance, session_id, patient_name, figs_list=None):
    """
        Exporte les rÃ©ponses du LLM pour un patient donnÃ© dans un fichier Markdown.

        Cette fonction extrait l'ensemble des rÃ©ponses associÃ©es Ã  une session utilisateur
        via le gestionnaire de sessions, puis les enregistre dans un fichier `.md`
        dans un dossier structurÃ© par patient et date. Elle peut Ã©galement inclure
        des graphiques (figures Plotly) si fournis.

        Args:
            session_manager_instance : Instance de SessionManager utilisÃ©e pour accÃ©der aux rÃ©ponses.
            session_id (str) : Identifiant unique de la session.
            patient_name (str) : Nom du patient concernÃ© par l'export.
            figs_list (list, optionnel) : Liste de graphiques (objets Plotly) Ã  inclure dans le fichier.

        Returns:
            str : Chemin absolu du fichier Markdown gÃ©nÃ©rÃ©.

        Raises:
            ValueError : Si aucune rÃ©ponse du LLM n'est disponible pour la session donnÃ©e.
        """
    # VÃ©rifications des arguments
    print("ðŸ” DÃ‰MARRAGE EXPORT")
    print(f"ðŸ“Œ session_id: {session_id}")
    print(f"ðŸ“Œ patient_name: {patient_name}")


    # RÃ©cupÃ©rer toutes les rÃ©ponses
    llm_responses = session_manager_instance.get_llm_responses(session_id)
    print(f"ðŸ§  Nombre de rÃ©ponses rÃ©cupÃ©rÃ©es : {len(llm_responses)}")

    if not llm_responses:
        print("âŒ Aucune rÃ©ponse Ã  exporter.")
        raise ValueError("Aucune rÃ©ponse du LLM Ã  exporter pour ce patient.")


    # ConcatÃ¨ne les rÃ©ponses avec des sÃ©parateurs pour plus de lisibilitÃ©
    final_text = "\n\n---\n\n".join(llm_responses)


    # Chemin d'export
    today = datetime.today().strftime("%Y-%m-%d")
    export_dir = MARKDOWN_CHAT_EXPORTS / patient_name / today
    export_dir.mkdir(parents=True, exist_ok=True)


    # Fichier final
    file_path = export_dir / f"export_chat_{patient_name}.md"


    # Ã‰criture Markdown
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(final_text)

        # Si des figures sont fournies
        if figs_list:
            print(f'type(figs_list[0] --> "{type(figs_list[0])}")')
            f.write("\n\n## Graphique des constantes du patient\n\n")

            for i, fig in enumerate(figs_list):
                image_path = os.path.join(export_dir, f"{patient_name}_graph_{i + 1}.png")
                fig.write_image(image_path)
                f.write(f"![Graphique {i + 1}]({os.path.basename(image_path)})\n\n")


    print(f"âœ… Export Markdown terminÃ© : {file_path}")
    return str(file_path)

