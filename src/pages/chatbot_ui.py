"""
Interface utilisateur du chatbot OBY-IA (page Dash `/chatbot`).

Ce module dÃ©finit lâ€™interface graphique de la page chatbot de lâ€™application OBY-IA.
Il gÃ¨re :
- lâ€™affichage des constantes mÃ©dicales du patient (graphique, tableau, anomalies),
- la dÃ©tection de lâ€™intention utilisateur Ã  partir dâ€™une saisie libre,
- la gÃ©nÃ©ration automatique de contenu (PPA, plan de soins, recommandations),
- lâ€™enregistrement et lâ€™affichage de lâ€™historique des Ã©changes avec le LLM,
- lâ€™export de la session au format Markdown,
- lâ€™affichage des dÃ©tails dans une fenÃªtre modale.

Ce module repose sur Dash, Dash Bootstrap Components et une logique centralisÃ©e via `session_manager_instance`.
"""





import dash
from dash import dcc, html, callback, ctx
from dash.dependencies import Input, Output, State
import dash_bootstrap_components as dbc
import markdown
from dash import MATCH



from src.llm_user_session.session_manager_instance import session_manager_instance
from src.func.extract_patient_name import extract_patient_name_llm
from src.func.generate_ppa_from_poa import process_ppa_request
from src.func.generate_structured_medical_plan import generate_structured_medical_plan
from src.func.llm_prompts import system_prompt, system_prompt_medical_plan
from src.func.extract_user_intent import detect_user_intent
from src.func.get_patient_constants_graphs import process_patient_request_with_constants
from src.func.get_patient_constants_graphs import analyze_constants
from src.func.extract_patient_name import extract_patient_name_llm
from src.utils.export_chat_response import export_llm_responses
from src.func.serialize_figs import serialize_figs, deserialize_figs
from src.utils.vector_db_utils import is_chroma_index_ready

from config.config import USER_DATABASE


dash.register_page(__name__, path="/chatbot")


# Layout
layout = dbc.Container([

    dcc.Store(id="session_data", storage_type="session"),
    dcc.Store(id="current_patient"),
    dcc.Store(id="constants_graphs_store", data=None),
    dcc.Store(id="chat_history", data=[], storage_type="session"),

dcc.Interval(id="index_check_interval", interval=2000, n_intervals=0),

html.Div(children=[
    dbc.Alert("Initialisation en cours... L'index de recherche est en cours de prÃ©paration.",
              color="warning",
              className="mt-4",
              style={"textAlign": "center"})
], style={"display": "block"}, id="index_banner_container"),

    dbc.Row([
        # Colonne gauche : Chat principal
        dbc.Col([
            html.H2("OBY - CHAT", className="text-center mb-4"),

            html.Div([
                html.P("Bonjour, comment puis-je vous aider ?", style={"fontStyle": "italic", "color": "#555"}),

                dbc.Input(id="user_input", placeholder="Posez votre question...", type="text", className="mb-2", disabled=True),

                dbc.Button("Envoyer", id="send_button", color="success", className="mb-2", style={"marginRight": "10px"}, disabled=True),
                dbc.Button("DÃ©connexion", id="logout_button", color="danger", className="mb-2", style={"float": "right"}),

                dcc.Loading(
                    id="loading_spinner",
                    type="circle",
                    children=[
                        html.Div(id="chat_history_display", className="chat-history")
                    ]
                ),
                # â†’ Ajout : Zone export
                html.Div([
                    html.Label("Exporter l'historique du LLMâ€¯:", style={"marginTop": "10px"}),
                    dbc.Button(
                        "ğŸ’¾ Exporter en Markdown",
                        id="export_button",
                        color="info",
                        className="mt-2",
                        style={"width": "100%"}
                    ),
                    html.Div(id="export_feedback", className="mt-2", style={"color": "green"})
                ]),
            ],
                style={
                    "border": "1px solid #ccc",
                    "borderRadius": "10px",
                    "padding": "15px",
                    "boxShadow": "2px 2px 10px rgba(0,0,0,0.1)"
                })
        ], width=7),

        # Colonne droite : DonnÃ©es mÃ©dicales
        dbc.Col([
            html.H4("-- SUIVI MEDICAL --", className="text-center mb-3"),

            dbc.Accordion([
                dbc.AccordionItem(
                    children=html.Div(id="constants_graphs"),
                    title="-> GRAPHIQUE DES CONSTANTES"
                ),
                dbc.AccordionItem(
                    children=html.Div(id="constants_table"),
                    title="-> TABLEAU DES CONSTANTES"
                ),
                dbc.AccordionItem(
                    children=html.Div(id="anomalies_summary"),
                    title="-> ANOMALIES POTENTIELLES DETECTEES"
                )
            ], start_collapsed=True)
        ], width=5)
    ]),
],
fluid=True)

@callback(
    Output("chat_history", "data"),
    Output("constants_graphs", "children"),
    Output("constants_table", "children"),
    Output("anomalies_summary", "children"),
    Output("current_patient", "data"),
    Output("constants_graphs_store", "data"),
    Output("chat_history_display", "children"),


    Input("send_button", "n_clicks"),
    State("user_input", "value"),


    Input("logout_button", "n_clicks"),
    State("chat_history", "data"),

    State("session_data", "data"),
    State("current_patient", "data"),
    prevent_initial_call=True
)
def handle_user_input_or_logout(send_clicks, user_input, logout_clicks, chat_history, session_data, current_patient):
    """
    Callback principal de gestion des interactions utilisateur.

    Cette fonction gÃ¨re :
    - la dÃ©connexion de lâ€™utilisateur,
    - la dÃ©tection de lâ€™intention (consultation de constantes, gÃ©nÃ©ration de PPA ou plan de soins),
    - lâ€™appel au modÃ¨le LLM pour produire une rÃ©ponse appropriÃ©e,
    - lâ€™affichage et la mise Ã  jour de lâ€™historique et des donnÃ©es patient.

    Args:
        send_clicks (int) : Nombre de clics sur le bouton "Envoyer".
        user_input (str) : Message saisi par lâ€™utilisateur.
        logout_clicks (int) : Nombre de clics sur le bouton "DÃ©connexion".
        chat_history (list) : Liste des messages actuellement affichÃ©s.
        session_data (dict) : DonnÃ©es de session utilisateur (user_id, session_id).
        current_patient (str) : Nom du patient actuellement sÃ©lectionnÃ©.

    Returns:
        tuple : Mise Ã  jour de :
            - l'historique du chat,
            - les graphiques et tableaux des constantes,
            - le rÃ©sumÃ© des anomalies,
            - le nom du patient actif,
            - les figures sÃ©rialisÃ©es,
            - lâ€™affichage du chat.
    """

    triggered = ctx.triggered_id
    print(f"ğŸ“Œ Callback triggered by: {triggered}")

    # --- Gestion de la dÃ©connexion ---
    if triggered == "logout_button":
        print("ğŸ”´ DÃ©connexion demandÃ©e")
        if session_data:
            session_manager_instance.end_session(session_data["user_id"], session_data["session_id"])
        return "", "", "", "", None


    # --- VÃ©rification session ---
    if not session_data or not isinstance(session_data, dict):
        # âš ï¸ Pas de session active
        return "âŒ Session non authentifiÃ©e. Veuillez vous reconnecter.", "", "", "", dash.no_update

    print("ğŸš€ chatbot_ui.py chargÃ© !")

    # --- Initialisation des blocs d'affichage et variables de retour ---
    figs_list = []
    table_html = ""
    anomaly_block = ""
    user_id = session_data.get("user_id")
    session_id = session_data.get("session_id")
    serialized_figs = None  # Valeur par dÃ©faut
    bot_response = []  # Liste pour pouvoir itÃ©rer mÃªme si vide
    bot_msg = None




        # --- Initialisation demande ---
    bot_response = "ğŸ¤– Je traite votre demande..."


    # --- Extraction de lâ€™intention ---
    print(f'âš ï¸dÃ©marrage dÃ©tection intentions-chatbot-ui.py...')
    intent_dict = detect_user_intent(user_input)

    nom = extract_patient_name_llm(user_input)

    intent = intent_dict.get("intent", "unknown")

    ppa_requested = intent == "generate_ppa"
    constantes_requested = intent == "get_constants"
    recommandations_requested = intent == "generate_recommendations"

    print(f"ğŸ¯ Intentions dÃ©tectÃ©es : "
          f"recommandations: {recommandations_requested},"
          f"constantes={constantes_requested}, "
          f"ppa={ppa_requested}, "
          f"nom patient={nom}")
    if ppa_requested or constantes_requested or recommandations_requested:
        print(f'âœ…dÃ©tection intention rÃ©ussie')


    # --- RÃ©initialisation si changement de patient ---
    if nom and (ppa_requested or constantes_requested or recommandations_requested):
        if nom and nom != current_patient:
            print(f"ğŸ†• Changement de patient dÃ©tectÃ© : {current_patient} â¡ï¸ {nom}")
            chat_history = []
            figs_list = []
            table_html = ""
            anomaly_block = ""
            current_patient = nom
            # Remet Ã  zÃ©ro le mapping dâ€™anonymisation
            session_manager_instance.reset_anonymization_mapping(user_id)
            session_manager_instance.set_current_patient(session_id, nom)

        else:
            print(f"âœ… Patient conservÃ© : {current_patient}")



    # --- Traitement des constantes ---
    if constantes_requested:
        try:
            print("ğŸ“Š Appel Ã  process_patient_request_with_constants()")
            bot_response, figs_list, table_html, anomaly_block = process_patient_request_with_constants(nom)
            serialized_figs = serialize_figs(figs_list)
        except Exception as e:
            print(f"âŒ Erreur dans process_patient_request_with_constants : {e}")
            bot_response = "Une erreur est survenue pendant le traitement des constantes."
            figs_list, table_html, anomaly_block = [], "", ""


    # --- Traitement demande PPA ---
    elif ppa_requested:
        print("ğŸ“„ Appel Ã  process_ppa_request() pour le PPA")
        try:
            bot_response, dict_mapping= process_ppa_request(user_input, system_prompt)

            # Enregistrer le mapping renvoyÃ© par la fonction dans la session
            # Le rÃ©cupÃ©rer proprement via session_manager.get_anonymization_mapping()
            session_manager_instance.set_anonymization_mapping(session_id, dict_mapping)

            # Quand le LLM a donnÃ© une rÃ©ponse (bot_response), ajout de la rÃ©ponse dans la session
            session_manager_instance.append_llm_response(session_id, bot_response)

            figs_list, table_html, anomaly_block = [], "", ""

        except Exception as e:
            print(f"âŒ Erreur dans process_ppa_request : {e}")
            bot_response = "Une erreur est survenue pendant la gÃ©nÃ©ration du PPA."
            figs_list, table_html, anomaly_block = "", "", ""



    # --- Traitement demande plan de soins ---
    elif recommandations_requested:
        print("ğŸ“„ Appel Ã  generate_structured_medical_plan() pour plan de soins")
        try:
            bot_response, dict_mapping= generate_structured_medical_plan(user_input, system_prompt_medical_plan)

            # Enregistrer le mapping renvoyÃ© par la fonction dans la session
            # Le rÃ©cupÃ©rer proprement via session_manager.get_anonymization_mapping()
            session_manager_instance.set_anonymization_mapping(session_id, dict_mapping)

            # Quand le LLM a donnÃ© une rÃ©ponse (bot_response), ajout de la rÃ©ponse dans la session
            session_manager_instance.append_llm_response(session_id, bot_response)

            figs_list, table_html, anomaly_block = [], "", ""

        except Exception as e:
            print(f"âŒ Erreur dans generate_structured_medical_plan : {e}")
            bot_response = "Une erreur est survenue pendant l'extraction des recommandations de soins."
            figs_list, table_html, anomaly_block = [], "", ""


    # Test
    if not any([ppa_requested, constantes_requested, recommandations_requested]):
        print("â— Aucune intention dÃ©tectÃ©e dans la requÃªte utilisateur.")


    # --- Correspondance avec Output() du layout ---
    constants_graphs = [dcc.Graph(figure=fig) for fig in figs_list]
    constants_table = None if not table_html else html.Div(table_html)
    anomaly_graphs = None if not anomaly_block else html.Div(anomaly_block)

    # ğŸ’¡ Ajout de la requÃªte utilisateur
    user_input_str = str(user_input).strip() if user_input else ""
    print(f"user_input brut: {user_input}")
    print(f"user_input_str aprÃ¨s nettoyage: '{user_input_str}'")

    # Si l'input est vide, on bloque l'exÃ©cution
    if not user_input_str:
        print("âš ï¸ Aucun texte saisi, arrÃªt du traitement.")
        return (
            dash.no_update, constants_graphs, constants_table, anomaly_graphs,
            current_patient, serialized_figs
        )

    user_msg = html.Div(f"ğŸ‘¤ {user_input_str}", className="user-message")
    chat_history.append(user_msg)

    # ğŸ’¡ Cas PPA / constantes / web
    if bot_response:
        bot_msg = html.Div(
            dcc.Markdown(str(bot_response), dangerously_allow_html=False),
            className="bot-response"
        )
        chat_history.append(bot_msg)

    chat_history_display = chat_history

    # ğŸ’¡ Retour de l'ensemble : un seul historique pour affichage + store
    return chat_history, constants_graphs, constants_table, anomaly_graphs, current_patient, serialized_figs, chat_history_display




@callback(
    Output("export_feedback", "children"),
    Input("export_button", "n_clicks"),
    State("session_data", "data"),
    State("current_patient", "data"),
    State("constants_graphs_store", "data"),
    prevent_initial_call=True
)
def export_chat_response(n_clicks, session_data, current_patient, serialized_figs):
    """
    Callback de gestion de lâ€™export de lâ€™historique du LLM au format Markdown.

    Cette fonction est appelÃ©e lorsquâ€™un utilisateur clique sur le bouton
    "Exporter". Elle dÃ©sÃ©rialise les graphiques, rÃ©cupÃ¨re les rÃ©ponses enregistrÃ©es
    dans la session, puis appelle la fonction `export_llm_responses`.

    Args:
        n_clicks (int) : Nombre de clics sur le bouton dâ€™export.
        session_data (dict) : DonnÃ©es de session (user_id, session_id).
        current_patient (str) : Nom du patient actif.
        serialized_figs (list) : Graphiques des constantes sÃ©rialisÃ©s.

    Returns:
        str : Message de confirmation ou dâ€™erreur selon le succÃ¨s de lâ€™export.
    """

    if not session_data:
        return "âŒ Session non authentifiÃ©e. Veuillez vous reconnecter."

    session_id = session_data["session_id"]

    try:
        constants_graphs = deserialize_figs(serialized_figs)
        file_path = export_llm_responses(
            session_manager_instance,
            session_id,
            current_patient,
            constants_graphs
        )
        return f"âœ… Export Markdown enregistrÃ© : {file_path}"
    except Exception as e:
        return f"âŒ Erreur lors de lâ€™export : {e}"


@callback(
    Output("index_banner_container", "style"),
    Output("user_input", "disabled"),
    Output("send_button", "disabled"),
    Input("index_check_interval", "n_intervals"),
)
def check_index_status(n):
    """
    Callback pÃ©riodique pour vÃ©rifier la disponibilitÃ© de l'index ChromaDB.

    Ce callback est dÃ©clenchÃ© toutes les 2 secondes via `dcc.Interval`.
    Il vÃ©rifie si le fichier `index_ready.flag` est prÃ©sent.
    Lorsque l'index est prÃªt, il :
    - Cache la banniÃ¨re d'attente
    - Active les composants dâ€™entrÃ©e utilisateur

    Args:
        n (int) : Nombre dâ€™intervalles Ã©coulÃ©s.

    Returns:
        tuple : Styles de la banniÃ¨re, Ã©tat des composants dâ€™entrÃ©e.
    """
    if is_chroma_index_ready():
        return {"display": "none"}, False, False
    else:
        return {"display": "block"}, True, True

