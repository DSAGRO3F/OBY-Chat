
# ğŸš€ DÃ©ploiement Docker â€“ OBY-Chat (nouvelle version du le 26-07-2025)

## ğŸ—‚ï¸ Projet : OBY-Chat

OBY-Chat est une application conversationnelle (Dash + IA) pour le traitement des documents de santÃ©, la gÃ©nÃ©ration de plans personnalisÃ©s d'accompagnement (PPA), et l'analyse des constantes mÃ©dicales des patients.  
Elle inclut Ã©galement un site de documentation technique complet basÃ© sur MkDocs.

---

## ğŸ¯ Objectif du dÃ©ploiement

- DÃ©ployer rapidement OBY-Chat via un **package Docker complet** (image + container)
- Offrir deux modes de fonctionnement :
  - `APP_MODE=app` â†’ Interface Dash (application par dÃ©faut)
  - `APP_MODE=doc` â†’ Site de documentation MkDocs

---

## ğŸ§¾ Arborescence essentielle

```
ğŸ“¦ OBY-Chat
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.override.yml
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ start.sh
â”œâ”€â”€ src/
â”œâ”€â”€ docs/
â”œâ”€â”€ assets/
â”œâ”€â”€ outputs/
â”œâ”€â”€ config/
â””â”€â”€ requirements.txt / pyproject.toml
```

---

## âš™ï¸ Fonctionnement gÃ©nÃ©ral

Le comportement de l'application dÃ©pend de la variable d'environnement `APP_MODE` :

- `APP_MODE=app` ou vide â†’ Lance lâ€™interface utilisateur OBY-Chat (Dash)
- `APP_MODE=doc` â†’ Lance le site de documentation technique (MkDocs)

Le fichier `scripts/start.sh` sâ€™occupe de dÃ©tecter ce mode et dâ€™exÃ©cuter la bonne commande.

---

## ğŸ³ DÃ©ploiement avec Docker

### 1. ğŸ—ï¸ Construction de lâ€™image (âš ï¸ dÃ©jÃ  faite)

Lâ€™image Docker est **dÃ©jÃ  construite** avant livraison du package.

> âœ… Vous **nâ€™avez pas besoin dâ€™exÃ©cuter** `docker build`.

---

### 2. âœ… Lancement de lâ€™application (mode app)

```bash
docker compose up -d
```

AccÃ©der Ã  lâ€™interface :

```
http://localhost:8050
```

---

### 3. âœ… Rebuild aprÃ¨s modifications (rÃ©servÃ© au dÃ©veloppeur)

Si vous modifiez le code source :

```bash
docker compose down
docker compose build
docker compose up -d
```

---

### 4. âœ… Volumes montÃ©s (override)

Le fichier `docker-compose.override.yml` permet de monter des volumes en local pour un usage en dÃ©veloppement.

---

### 5. âœ… Lancement du site de documentation (mode doc)

Vous pouvez aussi dÃ©marrer **uniquement le site de documentation MkDocs** :

```bash
docker run -p 8080:8080 -e APP_MODE=doc oby-chat
```

Puis ouvrir :

```
http://localhost:8080
```

> ğŸ“š Ce mode utilise `mkdocs serve` Ã  lâ€™intÃ©rieur du container.

---

### 6. âœ… Revenir au mode application

1. ArrÃªter le container documentation :

```bash
docker ps    # identifier lâ€™ID du container actif
docker stop <container_id>
```

2. RedÃ©marrer OBY-Chat en mode application :

```bash
docker compose up -d
```

---

### 7. âœ… Fichiers Ã  ignorer (extrait de `.gitignore`)

```
__pycache__/
*.pyc
.env
*.sqlite
outputs/pdf/
outputs/plots/
```

---

### 8. âœ… Nettoyage

Supprimer tous les containers, images, volumes (âš ï¸ avec prÃ©caution) :

```bash
docker system prune -a
```

---

## âœ… RÃ©sumÃ© des commandes

| Objectif                          | Commande                                                                 |
|----------------------------------|--------------------------------------------------------------------------|
| DÃ©marrer OBY-Chat (interface)    | `docker compose up -d`                                                  |
| ArrÃªter OBY-Chat                 | `docker compose down`                                                   |
| Lancer la documentation MkDocs   | `docker run -p 8080:8080 -e APP_MODE=doc oby-chat`                      |
| AccÃ©der Ã  OBY-Chat               | http://localhost:8050                                                   |
| AccÃ©der Ã  la documentation       | http://localhost:8080                                                   |

---




















# ============================================================
# Ancienne version deploiement.md (mise de cÃ´tÃ© le 26-07-2025)
# ============================================================

# ğŸ“¦ DÃ©ploiement Docker

## Projet : OBY-IA â€“ Agent conversationnel mÃ©dical pour l'accompagnement des personnes Ã¢gÃ©es
### Objectif du dÃ©ploiement
- Ce module dÃ©crit la procÃ©dure complÃ¨te pour dÃ©ployer localement l'application OBY-IA Ã  lâ€™aide de Docker.
- Lâ€™objectif est de fournir un environnement reproductible pour lancer l'interface Dash, interagir avec le chatbot, visualiser les constantes de santÃ©, gÃ©nÃ©rer des plans d'accompagnement personnalisÃ©s, et exporter les Ã©changes.

### ğŸ“ Arborescence essentielle
``` 
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.override.yml
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ src/
â”œâ”€â”€ config/
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ chat_exports/
â”œâ”€â”€ docs/
â”œâ”€â”€ scripts/

```

### Fonctionnement gÃ©nÃ©ral
#### L'application OBY-IA repose sur :

- Un agent conversationnel basÃ© sur des LLMs (Mistral, OpenAI)
- Une interface web construite avec Dash
- Une gestion de sessions utilisateurs avec historique
- Des exports en Markdown des rÃ©ponses gÃ©nÃ©rÃ©es
- Une Dockerisation complÃ¨te (image lÃ©gÃ¨re, config reproductible)

### Configuration : variables dâ€™environnement
#### ğŸŸ¢ Le fichier .env contient les clÃ©s nÃ©cessaires Ã  lâ€™accÃ¨s aux APIs :

- OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
- MISTRAL_API_KEY=hf_xxxxxxxxxxxxxxxxxxxxxxx
- Ce fichier ne doit pas Ãªtre versionnÃ© dans Git : il est protÃ©gÃ© par .gitignore.

### DÃ©ploiement avec Docker

#### 1. ğŸ—ï¸ Construction de lâ€™image
docker compose build

#### 2. âœ… Lancement de lâ€™application
docker compose up
L'application sera disponible Ã  l'adresse :
http://localhost:8050

#### 3. âœ… Rebuild aprÃ¨s modifications
Si vous changez des fichiers sources (src/, config/, etc.) :
docker compose down
docker compose up --build

#### 4. âœ… Volumes montÃ©s (override)
- Le fichier docker-compose.override.yml permet de monter les volumes pour un environnement de dÃ©veloppement :

- volumes:
  - ./src:/app/src
  - ./config:/app/config
  - ./scripts:/app/scripts
  - ./docs:/app/docs
  - ./src/data:/app/src/data
  - ./outputs:/app/outputs

- Ces volumes garantissent la persistance des donnÃ©es locales (exports, fichiers patients, graphiques...).

#### 5. âœ… Gestion des sessions
- Chaque utilisateur dispose dâ€™un user_id et session_id spÃ©cifiques
- Les Ã©changes avec le LLM sont enregistrÃ©s dans la mÃ©moire de session
- Les rÃ©ponses peuvent Ãªtre exportÃ©es en Markdown dans outputs/chat_exports/<nom_patient>/

#### 6. âœ… VÃ©rification post-dÃ©ploiement
- AprÃ¨s le lancement :
- AccÃ©dez Ã  lâ€™interface sur localhost:8050
- Authentifiez-vous avec un user_id et mot de passe
- Demandez un plan (PPA) ou des recommandations.
  - "PrÃ©pare un Plan PersonnalisÃ© d'Accompagnement du patient Deloin"
  - "Monsieur Deloin vient de faire une chute, donne moi la conduite Ã  tenir"
- Testez lâ€™export Markdown via le bouton dÃ©diÃ©
- VÃ©rifiez lâ€™arborescence : outputs/chat_exports/<patient>/<date>/export_chat_<patient>.md

#### 7. âœ… Fichiers Ã  ignorer (extrait de .gitignore)
- â–¶ï¸ Fichiers sensibles
- .env
- â–¶ï¸ OS
- .DS_Store

#### 8. âœ… Nettoyage
Pour tout rÃ©initialiser :
docker compose down -v --remove-orphans

#### ğŸ†˜ Support
- Pour tout problÃ¨me de clÃ© API, vÃ©rifier le fichier .env
- Pour le debug des logs : consulter la sortie du terminal (docker compose logs)
- En cas de besoin : reconstruire lâ€™image docker compose build --no-cache
